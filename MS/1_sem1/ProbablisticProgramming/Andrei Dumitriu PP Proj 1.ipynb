{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Andrei Dumitriu, Artificial Intelligence MS, 2020, Group 507**\n",
    "\n",
    "This notebook explores Topic Modeling using pymc. We have implemented LDA (Latent Dirichlet Allocation) and have explored some methods and different approaches to topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/irikos/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/irikos/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pymc as pm\n",
    "import numpy as np\n",
    "import copy \n",
    "\n",
    "import os\n",
    "import nltk\n",
    "import wikipedia\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import seaborn as sns\n",
    "# from pycontractions import Contractions\n",
    "# cont = Contractions('GoogleNews-vectors-negative300.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONTROL VARIABLES**\n",
    "1. *SANITY_CHECK* \n",
    "- SET TO TRUE IF YOU WANT TO TEST ON SANITY CHECK\n",
    "- SET TO FALSE IF YOU WANT TO TEST ON WIKIPEDIA PAGES\n",
    "\n",
    "2.*CLEAR_DATA* \n",
    "- SET TO TRUE IF YOU WANT TO APPLY NLP TECHNIQUES (stemming, lemming, removing stopwords etc) on the corpus\n",
    "- SET TO FALSE IF YOU WANT TO KEEP THE DOCUMENTS IN ORIGINAL FORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "SANITY_CHECK = False\n",
    "CLEAR_DATA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET SANITY CHECK TO TRUE IF YOU WANT TO TEST ON SANITY CHECK\n",
    "# SET SANITY CHECK TO FALSE IF YOU WANT TO TEST ON WIKIPEDIA PAGES\n",
    "docs = []\n",
    "new_doc = []\n",
    "\n",
    "if (SANITY_CHECK == True):\n",
    "    docs = [[\"aaa\", \"bbb\", \"aaa\"], \n",
    "        [\"bbb\", \"aaa\", \"bbb\"], \n",
    "        [\"aaa\", \"bbb\", \"bbb\", \"aaa\"], \n",
    "        [\"uuu\", \"vvv\"], \n",
    "        [\"uuu\", \"vvv\", \"vvv\"], \n",
    "        [\"uuu\", \"vvv\", \"vvv\", \"uuu\"]]\n",
    "    new_doc = [\"aaa\", \"bbb\", \"aaa\", \"bbb\", \"uuu\"]\n",
    "else: \n",
    "    \n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    # splitting the sentence into words\n",
    "    page1 = wikipedia.page('Rockets')\n",
    "    doc1 = tokenizer.tokenize(page1.content)[:1000] # only way to run it in this lifetime\n",
    "    page2 = wikipedia.page('Exploration, Space') \n",
    "    doc2 = tokenizer.tokenize(page2.content)[:1000] # only way to run it in this lifetime\n",
    "    \n",
    "    docs.append(doc1)\n",
    "    docs.append(doc2)\n",
    "    \n",
    "    new_page = wikipedia.page('Jupyter')\n",
    "    new_doc = tokenizer.tokenize(new_page.content)[:1000] # only way to run it in this lifetime\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NLP MAGIC**\n",
    "\n",
    "We are going to apply some NLP magic, such as stemming, lemming and removing stopwords. This will greatly help us in better identifying the underlying topic structure.\n",
    "\n",
    "1. Split the text into words\n",
    "2. Lowercase all of them\n",
    "3. Remove all the stopwords\n",
    "4. Apply snowball stemmer (careful, this can also decrease accuracy. For example, it will change 'meaning' into 'mean', which can have a different ...meaning\n",
    "5. Apply word lemmatization\n",
    "6. Enjoy, but do test it with and without clearing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_data(doc):\n",
    "    # expanding words: for example, \"we're\" into \"we are\". Had an error when installing pycontractions, but should work like this\n",
    "    #doc = list(cont.expand_texts([doc], precise=True))\n",
    "    \n",
    "    # lowercase all the words\n",
    "    l_words = [word.lower() for word in doc if word.isalnum()]\n",
    "    # remove stopwords\n",
    "    sw = stopwords.words('english')\n",
    "    l_words_sw = [word for word in l_words if word not in stopwords.words('english')]\n",
    "    \n",
    "#     # applying a stemmer (snowball) on each of the words thata are left\n",
    "    snb = nltk.SnowballStemmer('english')\n",
    "    l_words_snb = [snb.stem(word) for word in l_words_sw]\n",
    "    \n",
    "    # apply a lemmatizerr\n",
    "    lem = WordNetLemmatizer()\n",
    "    l_words_lem = [lem.lemmatize(word) for word in l_words_snb]\n",
    "    return l_words_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (CLEAR_DATA == True):\n",
    "    cleared_docs = []\n",
    "    for doc in docs:\n",
    "        cleared_docs.append(clear_data(doc))\n",
    "    docs = cleared_docs\n",
    "    new_doc = clear_data(new_doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ground info**\n",
    "We have created the LDA class that encompasses all the functionality we need.\n",
    "\n",
    "The following variables are important:\n",
    "\n",
    "K - number of topics \n",
    "\n",
    "M - number of documents \n",
    "\n",
    "V - vocabulary length\n",
    "\n",
    "Most of the functions are explained in the comments or ar self-explanatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDA():\n",
    "    # constructor\n",
    "    def __init__(self, docs, K, alpha_scalar, beta_scalar):\n",
    "        \n",
    "        # K is the number of topics\n",
    "        self.K = K\n",
    "        \n",
    "        self.initialize_vocabulary(docs)\n",
    "        \n",
    "        self.alpha = np.ones(self.K) * alpha_scalar\n",
    "        self.beta = np.ones(self.V) * beta_scalar\n",
    "        \n",
    "    # create the vocabulary; in index_data we have the documents with words_indexes instead of actual words\n",
    "    def initialize_vocabulary(self, docs):\n",
    "        self.vocabulary = self.create_vocabulary(docs)\n",
    "        self.index_data = self.replace_words_with_index(docs, self.vocabulary)\n",
    "        \n",
    "        # M is the number of docs\n",
    "        self.M = len(docs)\n",
    "        \n",
    "        # number of unique words\n",
    "        self.V = len(self.vocabulary)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def initialize_distributions(self):\n",
    "        # Theta is the document distribution over the topic space\n",
    "        self.theta_i = np.empty(self.M, dtype=object)\n",
    "        self.theta = np.empty(self.M, dtype=object)\n",
    "        for i in range(self.M):\n",
    "            self.theta_i[i] = pm.Dirichlet(\"theta_i_%i\" % i, theta = self.alpha)\n",
    "            \n",
    "        self.theta_i = pm.Container(self.theta_i)\n",
    "        \n",
    "        for i in range(self.M):\n",
    "            self.theta[i] = pm.CompletedDirichlet(\"theta_%i\" % i, self.theta_i[i])\n",
    "        \n",
    "        self.theta = pm.Container(self.theta)\n",
    "        \n",
    "        # Phi is the word distribution for the topic space\n",
    "        self.phi_i = np.empty(self.K, dtype=object)\n",
    "        self.phi = np.empty(self.K, dtype=object)\n",
    "        \n",
    "        \n",
    "        for i in range(self.K):\n",
    "            self.phi_i[i] = pm.Dirichlet(\"phi_i_%i\" % i, theta = self.beta)\n",
    "            \n",
    "        self.phi_i = pm.Container(self.phi_i)\n",
    "        \n",
    "        for i in range(self.K):\n",
    "            self.phi[i] = pm.CompletedDirichlet(\"phi_%i\" % i, self.phi_i[i])\n",
    "        \n",
    "        self.phi = pm.Container(self.phi)\n",
    "        \n",
    "        # Zeeta is the word-topic mapping        \n",
    "        self.zeeta = np.empty(self.M, dtype=object)\n",
    "        for i in range(self.M):\n",
    "            self.zeeta[i] = pm.Categorical(\"zeeta_%i\" % i, p = self.theta[i], size = len(self.index_data[i]))\n",
    "            \n",
    "        self.zeeta = pm.Container(self.zeeta)\n",
    "        \n",
    "        \n",
    "        # W is the \n",
    "        self.w = pm.Container(\n",
    "            [                             # document d, word i\n",
    "                pm.Categorical(\"w_%i_%i\" % (d, i), \n",
    "                              p = pm.Lambda(\"phi_z_%i%i\" % (d, i), \n",
    "                                           lambda z = self.zeeta[d][i], phi = self.phi : phi[z]\n",
    "                                           ),\n",
    "                               value = self.index_data[d][i],\n",
    "                               observed = True\n",
    "                              )\n",
    "                for d in range(self.M) for i in range(len((self.index_data[d])))\n",
    "                    \n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.model = pm.Model([self.theta_i, self.theta, self.phi_i, self.phi, self.zeeta, self.w])\n",
    "        self.mcmc = pm.MCMC(self.model)\n",
    "        \n",
    "    \n",
    "    def get_params(self):\n",
    "        theta_mean = []\n",
    "        for i in range(self.M):\n",
    "            theta_mean.append(self.mcmc.trace(\"theta_%i\" % i)[:].mean(axis=0))\n",
    "        \n",
    "        phi_mean = []\n",
    "        \n",
    "        for i in range(self.K):\n",
    "            phi_mean.append(self.mcmc.trace(\"phi_%i\" % i)[:].mean(axis=0))\n",
    "        \n",
    "        return theta_mean, phi_mean\n",
    "    \n",
    "    def print_zeeta(self, size):\n",
    "        for i in range(self.M):\n",
    "            print(\"Doc_%i\" % i)\n",
    "            print(self.mcmc.trace(\"zeeta_%i\" % i)[0:size])\n",
    "        \n",
    "    def create_vocabulary(self, data):\n",
    "        index = 0\n",
    "        vocabulary = {}\n",
    "        for document in data:\n",
    "            for word in document:\n",
    "                if (word not in vocabulary.keys()):\n",
    "                    vocabulary[word] = index\n",
    "                    index += 1\n",
    "        return vocabulary\n",
    "\n",
    "    \n",
    "    def replace_words_with_index(self, data, vocabulary):\n",
    "        # damn it, python!\n",
    "        index_data = copy.deepcopy(data)\n",
    "        for doc_index, document in enumerate(data):\n",
    "            for word_index, word in enumerate(document):\n",
    "                index_data[doc_index][word_index] = vocabulary[word]\n",
    "\n",
    "        return index_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1**\n",
    "- Build the observed variable\n",
    "- Inferd the hidden topic structure\n",
    "- Trace also z (this is quite hard to print in a useful manner - what did you have in mind?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = LDA(docs, 2, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA.initialize_distributions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [-----------------100%-----------------] 10000 of 10000 complete in 173.1 sec"
     ]
    }
   ],
   "source": [
    "LDA.mcmc.sample(10000,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "(theta_mean, phi_mean) = LDA.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta mean:\n",
      "[[0.47180597 0.52819403]]\n",
      "[[0.63603516 0.36396484]]\n",
      "Phi mean:\n",
      "[[5.86692741e-04 6.19775277e-03 7.35752846e-03 1.07161649e-03\n",
      "  1.76303823e-05 1.88497091e-03 1.63934235e-05 9.27435343e-04\n",
      "  3.86840530e-04 9.30679540e-04 5.66137525e-04 4.28478629e-03\n",
      "  1.39373471e-04 9.40459737e-05 3.37390950e-04 1.09565852e-03\n",
      "  1.43278356e-04 4.22479076e-03 1.42505038e-03 1.94810989e-04\n",
      "  1.93341904e-04 6.12322715e-03 2.74794768e-05 2.06839383e-03\n",
      "  3.96339532e-03 2.02887135e-03 6.76325629e-06 1.05883584e-04\n",
      "  6.22664708e-04 2.88885013e-03 7.76083299e-04 2.29581607e-04\n",
      "  4.70026879e-03 1.96053538e-03 2.29597174e-04 2.09174733e-03\n",
      "  4.31353230e-04 5.08724795e-03 4.72601294e-05 1.71849511e-03\n",
      "  8.33754250e-04 1.00226664e-03 2.96178730e-06 8.12316331e-04\n",
      "  1.09940873e-03 5.61332054e-03 6.77176668e-05 7.90697056e-04\n",
      "  3.20215119e-03 7.77322166e-05 2.88793580e-04 9.15141397e-04\n",
      "  5.68412938e-04 2.29119513e-03 3.88728385e-04 8.43853916e-06\n",
      "  2.20323058e-04 2.38957432e-08 1.06941622e-05 3.14484787e-05\n",
      "  4.75581930e-03 7.14760221e-05 1.00564915e-03 1.99540373e-04\n",
      "  1.89604005e-03 3.54225509e-04 3.58110853e-04 4.93291804e-04\n",
      "  2.94963810e-06 5.29462038e-04 4.17197129e-03 7.88554998e-05\n",
      "  2.79571862e-03 7.10014362e-04 8.57540184e-04 1.62465759e-02\n",
      "  6.28167829e-06 1.62337352e-03 5.40755883e-03 5.15923883e-04\n",
      "  1.04720746e-04 2.04585766e-03 7.79054378e-06 1.01690457e-03\n",
      "  5.76835939e-03 1.71615103e-03 1.59978379e-04 6.65758190e-03\n",
      "  4.66031737e-03 1.32347600e-03 2.45883643e-04 4.07448571e-04\n",
      "  1.08022853e-05 9.94476247e-04 1.67609176e-03 4.31762535e-03\n",
      "  3.71638521e-05 3.49954548e-04 9.57517310e-05 8.52626911e-04\n",
      "  5.04531241e-04 4.85342626e-05 4.16128188e-03 2.82941274e-04\n",
      "  3.81639208e-04 7.11160111e-03 1.82033082e-03 4.69398248e-04\n",
      "  2.45889981e-06 7.90686313e-04 2.59782359e-03 8.55665807e-04\n",
      "  8.42721360e-04 6.93854271e-03 1.10827429e-03 9.57626858e-04\n",
      "  1.29445568e-03 1.45381040e-04 2.02132610e-03 4.15528168e-04\n",
      "  5.41767157e-03 4.30457039e-04 1.36409174e-03 1.92315711e-03\n",
      "  4.57819426e-04 1.34075778e-04 1.08034399e-02 1.54293798e-04\n",
      "  3.85811450e-03 1.84142337e-04 1.84354543e-03 1.37615637e-04\n",
      "  5.00849741e-05 1.52750455e-03 4.17369133e-03 4.85310607e-03\n",
      "  1.02550935e-03 1.66398803e-03 3.13585008e-03 8.98080266e-06\n",
      "  1.30915263e-03 8.74778417e-05 2.09166215e-04 1.22262356e-03\n",
      "  1.10791376e-06 7.73304892e-04 2.55929104e-03 6.69594052e-04\n",
      "  2.31159731e-03 3.23081585e-03 7.68210018e-05 3.67755068e-04\n",
      "  3.42636923e-04 1.39419929e-05 8.90445516e-04 1.74302601e-04\n",
      "  5.91558129e-06 2.57022551e-04 5.51586021e-04 2.71847941e-03\n",
      "  2.56856828e-03 8.32192129e-04 1.79450473e-05 1.42386621e-03\n",
      "  1.15512673e-03 1.23791458e-04 3.49785543e-04 1.30238594e-03\n",
      "  7.83919163e-04 3.40932917e-03 2.52965147e-03 8.46241448e-05\n",
      "  1.06550671e-04 4.58714045e-04 1.03149911e-05 1.49877311e-04\n",
      "  1.52282703e-05 1.36369327e-05 2.62350371e-03 4.03054248e-04\n",
      "  1.09584045e-04 1.59383538e-03 2.89562286e-03 5.71484901e-04\n",
      "  1.59007125e-03 8.16215738e-04 8.97174094e-04 3.62390691e-03\n",
      "  2.75873812e-06 1.67730551e-03 3.09641625e-03 1.26624871e-03\n",
      "  5.39903530e-04 8.88915121e-04 1.73102472e-03 1.66018585e-03\n",
      "  6.70514521e-04 2.44535417e-03 6.32682583e-08 5.30972542e-04\n",
      "  1.80311187e-03 6.33750003e-04 1.39682866e-03 1.11298713e-06\n",
      "  1.07581315e-05 6.15128895e-05 3.63566291e-06 4.11575697e-03\n",
      "  4.97710758e-05 1.46490480e-04 2.87422220e-03 3.70466934e-04\n",
      "  2.02893043e-05 6.68005660e-04 7.00983359e-06 8.95493264e-05\n",
      "  3.80876388e-03 3.61632352e-05 1.54212145e-03 7.32847516e-03\n",
      "  1.27706044e-04 1.64449443e-04 1.76427649e-05 4.97202487e-05\n",
      "  2.67019018e-03 7.37373823e-04 1.29097140e-03 3.86783555e-03\n",
      "  6.14787753e-04 7.59548539e-08 6.62629626e-03 3.50973452e-03\n",
      "  4.23677202e-03 6.92581484e-04 1.08339804e-04 1.04818537e-05\n",
      "  4.64899119e-05 1.39786868e-03 5.58908271e-05 2.35777469e-03\n",
      "  5.75601860e-03 2.05083342e-03 2.36342670e-03 1.71958620e-05\n",
      "  2.36002970e-04 1.61255102e-03 1.00525430e-05 8.24738440e-04\n",
      "  3.58901931e-05 6.88555158e-04 1.68838272e-05 1.01312529e-03\n",
      "  2.29069369e-03 1.96016319e-04 1.06355936e-03 7.90596871e-05\n",
      "  6.35941417e-04 2.91819233e-04 1.09157748e-03 3.20504253e-04\n",
      "  5.77123628e-05 1.52518825e-03 3.51427421e-04 2.83789775e-03\n",
      "  1.22470439e-03 2.01471562e-03 6.27408820e-04 1.23559501e-02\n",
      "  3.83563981e-05 2.19459690e-03 4.14513161e-04 2.23601753e-04\n",
      "  8.58049450e-06 3.56369696e-03 6.93152729e-03 1.21955444e-03\n",
      "  5.16402518e-03 7.15544619e-05 2.03661432e-04 3.62681775e-04\n",
      "  1.09975085e-04 1.43172541e-03 2.66093248e-03 1.19079218e-04\n",
      "  3.80052921e-04 2.77615046e-04 3.10438834e-05 3.97707508e-03\n",
      "  1.92377853e-04 2.19725924e-03 1.85165498e-04 4.29597973e-07\n",
      "  3.22815128e-04 1.96869401e-03 4.13115437e-04 2.00735634e-05\n",
      "  2.27857540e-04 1.75566605e-04 3.53766821e-03 1.39156063e-03\n",
      "  2.66722717e-04 3.37048206e-03 1.14817981e-03 1.95617941e-04\n",
      "  9.97943577e-03 1.01401320e-03 1.47157536e-06 3.87820602e-04\n",
      "  7.23133897e-08 9.62994323e-04 9.98701667e-07 1.23388539e-03\n",
      "  1.28974446e-03 1.14187706e-03 8.22989022e-04 4.82379878e-03\n",
      "  2.74396625e-04 6.54712040e-03 1.64993536e-03 7.45992679e-04\n",
      "  1.68160028e-03 8.64913308e-03 1.77112190e-03 9.49211003e-04\n",
      "  1.81826191e-03 3.82702204e-03 2.45249718e-03 7.83556633e-06\n",
      "  8.97413008e-03 7.91193805e-04 1.44144192e-04 3.05178134e-03\n",
      "  4.35834635e-04 4.06920629e-03 1.26061322e-03 1.23984801e-03\n",
      "  3.23301480e-04 3.74258474e-03 2.57190871e-04 3.09815090e-04\n",
      "  7.75226523e-03 4.46981077e-04 2.29315500e-03 1.41997028e-04\n",
      "  1.42197725e-04 1.89305177e-03 4.71730622e-05 1.42995612e-02\n",
      "  6.81430755e-04 2.24671797e-04 6.44328250e-05 2.22360050e-03\n",
      "  9.07125627e-03 4.06140906e-03 2.62657883e-04 2.64809705e-04\n",
      "  2.95024777e-04 6.63347156e-03 5.57793593e-05 4.73927444e-03\n",
      "  2.40740377e-03 5.33818438e-05 6.29416791e-04 2.51115038e-04\n",
      "  1.05282729e-05 2.87686148e-05 1.20851208e-04 5.48155272e-06\n",
      "  3.25546147e-04 4.75924454e-04 8.38940628e-04 1.27191386e-03\n",
      "  4.71281657e-05 2.61596377e-04 1.47236665e-03 7.83538247e-04\n",
      "  6.21739408e-05 1.13210804e-05 1.60678065e-03 7.71004306e-06\n",
      "  1.69123170e-04 9.82626505e-05 6.63460501e-03 6.52971431e-05\n",
      "  3.84563158e-03 1.89242282e-04 1.32283941e-07 2.28852240e-03\n",
      "  9.15327767e-04 2.64331576e-04 2.19759118e-04 2.65800021e-04\n",
      "  3.92902084e-06 1.79469989e-04 1.15315889e-06 7.35739795e-04\n",
      "  6.26433597e-03 1.61624460e-03 4.55870157e-04 1.55628518e-04\n",
      "  2.15290380e-03 3.86257521e-03 3.34962231e-04 4.40514104e-05\n",
      "  4.73218391e-04 4.71633453e-04 4.46316547e-04 3.90633082e-05\n",
      "  2.38434102e-03 2.05896882e-03 2.85928200e-05 4.14386669e-03\n",
      "  2.73535885e-03 7.80846070e-05 2.90642765e-03 3.33840693e-04\n",
      "  1.15944802e-04 2.63756950e-08 1.64903321e-03 4.61412028e-05\n",
      "  1.67667752e-03 2.14191509e-10 6.19377422e-04 1.89244780e-03\n",
      "  1.39610694e-05 1.68803171e-04 2.52479984e-03 5.58443242e-04\n",
      "  5.78037385e-04 4.30546805e-03 1.84887918e-04 2.80458200e-03\n",
      "  5.82427592e-04 4.54641123e-04 2.97840081e-07 6.13709204e-04\n",
      "  1.45304567e-03 6.07698996e-09 7.25969839e-05 5.03003266e-03\n",
      "  6.13282687e-03 2.60918483e-05 4.24763879e-05 1.25747917e-04\n",
      "  1.34311722e-03 1.21977414e-04 4.92989929e-06 1.78011956e-04\n",
      "  1.08957201e-04 5.38215683e-06 6.49182337e-06 2.50352585e-03\n",
      "  1.10915879e-04 5.41825414e-03 4.57834888e-04 1.42377132e-03\n",
      "  1.06937788e-04 6.80985598e-06 5.57889218e-05 1.41871762e-04\n",
      "  1.52523710e-04 2.69856854e-03 2.17689519e-07 1.88544286e-04\n",
      "  4.09701641e-03 5.10359429e-04 3.19572222e-03 1.44439267e-03\n",
      "  9.28867724e-04 3.36697769e-04 8.80705547e-03 4.93042805e-04\n",
      "  2.89669386e-04 5.40114234e-03 9.48141693e-04 9.83965457e-05\n",
      "  1.49459686e-03 4.92284916e-04 1.94062324e-04 6.56579454e-03\n",
      "  3.21345705e-04 5.23810511e-04 7.82584062e-04 5.47100513e-05\n",
      "  2.76263524e-03 4.58417295e-03 2.06447919e-04 1.29953672e-03\n",
      "  2.86787796e-04 2.66632668e-05 6.31380865e-03 1.81429761e-04\n",
      "  1.59664009e-04 3.69957190e-03 1.67705831e-03 2.08189188e-04\n",
      "  1.30618186e-03 5.66534439e-04 8.38367234e-04 1.35398419e-05\n",
      "  4.02523074e-04 2.50848174e-03 1.32549334e-06 7.27093140e-04\n",
      "  3.01860622e-04 3.56781651e-04 4.56551631e-03 2.59959108e-03\n",
      "  9.60873493e-04 1.16868350e-03 3.08990797e-04 3.59271588e-03\n",
      "  1.51941598e-03 3.34698696e-03 9.04622355e-04 7.20417986e-05\n",
      "  1.51997961e-04 1.11952595e-03 1.13263201e-03 1.42771019e-04\n",
      "  3.18766737e-03 7.11947648e-04 2.74801725e-03 3.46245902e-04\n",
      "  4.81287701e-06 1.87369498e-06 7.69114406e-05 8.20866810e-04\n",
      "  2.23965906e-03 2.01276630e-03 9.88079871e-05 4.60787565e-03\n",
      "  3.37779206e-08 1.83940898e-03 5.22794034e-03 6.80119020e-04\n",
      "  7.85448129e-07 5.01437295e-08 1.69528999e-03 5.54083063e-03\n",
      "  3.45025159e-05 6.26478109e-03 4.23890680e-05 9.76834145e-05\n",
      "  9.53197166e-04 2.31488032e-04 6.20221322e-03 2.81805432e-04\n",
      "  1.30045429e-05 5.37501064e-04 3.94636269e-04 1.58676025e-03\n",
      "  1.11139868e-03 1.86252156e-03 5.43084687e-05 2.59032954e-02\n",
      "  9.89096667e-04 8.78302194e-05 1.00811406e-03 4.64706158e-08\n",
      "  5.19912632e-05 6.56199475e-04 3.40884980e-05 1.76680682e-03\n",
      "  6.99194507e-04 3.61525026e-03 9.29568568e-04 3.58000062e-04\n",
      "  1.20971903e-05 1.89884672e-05 4.62235330e-03 2.10282453e-04\n",
      "  1.10556810e-03 4.94302638e-04 1.61618018e-06 1.77067604e-04\n",
      "  8.58215821e-03 3.34105820e-04 1.62246304e-04 9.10014370e-05\n",
      "  1.16178069e-04 2.22534765e-05 2.48216202e-03 7.72599788e-06\n",
      "  4.45696875e-04 3.93499201e-03 1.75819994e-03 6.22768426e-04\n",
      "  5.08219921e-04 1.53002695e-04 1.19663169e-05 1.08125645e-04\n",
      "  2.97551601e-03 2.11821159e-04 4.79596265e-05 1.25949955e-04\n",
      "  5.33171545e-04 2.18885650e-03 2.48378368e-03 2.37308300e-03\n",
      "  6.27965561e-04 8.35011055e-06 2.32579395e-03 7.97557197e-04\n",
      "  7.62499505e-05 1.24432006e-04 1.16172129e-03 2.27545183e-04\n",
      "  1.48842056e-05 2.36873242e-04 1.20238124e-04 6.08992229e-03\n",
      "  5.45072254e-03 5.10332216e-04 1.98807306e-03 1.90591634e-04\n",
      "  1.41716859e-04 8.58462140e-04 1.75694352e-03 2.38496754e-05\n",
      "  2.36873049e-04 4.14989590e-03 7.16032658e-05 7.58393057e-04\n",
      "  3.19514155e-04 7.48576532e-05 1.17308881e-04 3.91769038e-03\n",
      "  7.56218101e-04 5.53391451e-05 1.97494492e-03 1.26326621e-03\n",
      "  1.58763265e-04 2.77955874e-04 1.18397650e-03 7.47587180e-04\n",
      "  3.46828785e-03 1.02295708e-03 1.35182612e-05 2.00556877e-03\n",
      "  2.71958630e-06 5.26276151e-04 1.36213846e-04 1.71896463e-03\n",
      "  5.34968038e-08 5.85109541e-04 1.29656816e-03 3.63786009e-04\n",
      "  1.86327464e-04 4.77434103e-04 7.90880268e-04 2.77579940e-05\n",
      "  7.84158231e-05 8.25869163e-05 3.74551209e-03 2.73950820e-03\n",
      "  4.06021030e-04 4.67222174e-04 1.60560593e-04 1.23940438e-04\n",
      "  2.34965454e-03 4.39810164e-06 2.53180521e-03 4.57339625e-03\n",
      "  1.99024095e-04 9.68621802e-05 1.05436739e-03 1.44488990e-03\n",
      "  2.45684753e-04 2.78612058e-03 8.66452753e-05 1.77355373e-03\n",
      "  5.40400497e-03 7.22107550e-04 2.32572934e-03 9.53877733e-06\n",
      "  1.17676059e-03 5.76000785e-05 4.23934129e-06 1.34773455e-03\n",
      "  3.23105578e-03 1.21868579e-04 1.62381087e-05 1.65436828e-03\n",
      "  4.58322511e-05 8.98970504e-05 2.16645261e-05 8.77523069e-04\n",
      "  1.27193262e-03 3.59594479e-03 2.04352226e-03 3.13683487e-03\n",
      "  2.49058706e-04 2.09213988e-04 3.50841429e-03 5.79687116e-03]]\n",
      "[[8.57505007e-03 2.30298697e-05 1.99959212e-05 7.64916990e-04\n",
      "  1.60377626e-05 8.27224046e-04 2.87168115e-04 8.41622308e-04\n",
      "  5.46882474e-04 1.01570363e-04 5.52727475e-04 1.96729080e-04\n",
      "  7.35089364e-03 1.40242892e-04 1.64946493e-03 6.43879701e-03\n",
      "  2.76105006e-03 1.17460263e-05 1.04775382e-03 5.31094535e-04\n",
      "  8.10003686e-04 1.63430844e-03 2.21017686e-04 2.67209306e-03\n",
      "  5.34652326e-04 1.60686660e-04 3.76077990e-06 7.31970443e-03\n",
      "  3.30715570e-04 1.52092024e-04 1.36069450e-03 1.45273690e-03\n",
      "  3.29633161e-03 1.88371670e-04 3.57652059e-03 1.86613626e-04\n",
      "  3.43401547e-05 6.63394012e-03 2.74867948e-03 9.67481148e-06\n",
      "  7.60657989e-04 5.55015751e-04 1.07086226e-03 2.86749292e-04\n",
      "  1.34974580e-03 1.50336822e-05 1.25872871e-03 4.70432709e-07\n",
      "  2.61943258e-05 6.80428162e-04 7.12571333e-06 3.86370210e-03\n",
      "  2.49181560e-04 1.39284840e-03 1.15304102e-02 9.79444666e-05\n",
      "  4.54928219e-04 3.14726450e-04 1.00256380e-04 9.11400981e-05\n",
      "  3.11331866e-04 2.59246283e-03 4.70849043e-04 2.37001724e-05\n",
      "  6.87746932e-04 1.93399905e-03 3.88258228e-04 9.75839555e-04\n",
      "  6.40205176e-03 8.02317262e-04 2.37288627e-03 8.41090274e-05\n",
      "  4.61684596e-05 9.74262507e-04 2.99808473e-04 3.86245944e-03\n",
      "  1.25480422e-04 1.08076806e-03 1.25103152e-04 3.11687422e-05\n",
      "  3.46957501e-03 3.46282969e-06 4.40451850e-04 1.36585424e-03\n",
      "  1.78837437e-03 6.92766643e-03 7.67577963e-03 1.98676308e-03\n",
      "  4.92399957e-05 7.06435297e-05 8.34629558e-04 8.46416405e-04\n",
      "  4.77951274e-04 5.54260231e-05 1.11787622e-03 2.14668755e-03\n",
      "  3.21049840e-04 4.09886314e-05 1.89035947e-03 2.21558374e-03\n",
      "  4.23747152e-05 2.76645441e-04 4.06790003e-04 4.15002209e-04\n",
      "  3.85367583e-03 2.06603977e-03 3.00526579e-04 1.85058321e-04\n",
      "  3.29478575e-04 2.43002928e-03 2.69279103e-08 5.16680338e-03\n",
      "  8.21301916e-04 5.99151618e-04 4.41989423e-03 2.39393064e-03\n",
      "  2.77883023e-04 7.95822640e-04 4.00727870e-05 6.15193269e-03\n",
      "  1.15092753e-04 2.00064105e-04 4.15306193e-04 8.03926494e-04\n",
      "  1.63892275e-05 1.32235608e-04 1.45872892e-04 2.52619386e-03\n",
      "  1.30812390e-03 5.14557963e-04 2.48694240e-03 6.20804526e-04\n",
      "  1.51072918e-04 7.43865203e-03 9.41183454e-04 1.07278175e-03\n",
      "  4.29454546e-04 3.34095102e-03 4.98201951e-04 6.01592572e-04\n",
      "  1.98861629e-04 4.60542851e-03 2.46358299e-03 6.06013616e-03\n",
      "  2.06561599e-03 2.06528986e-03 1.54375615e-02 1.06007741e-02\n",
      "  1.19724317e-03 4.79076833e-04 1.49180134e-04 7.50266798e-04\n",
      "  2.18922251e-04 1.83381218e-03 1.95333371e-06 1.17057061e-03\n",
      "  8.15596304e-04 3.52783342e-04 1.13302402e-03 6.09353459e-04\n",
      "  1.50222999e-03 1.20829788e-04 8.83811290e-04 6.89801810e-04\n",
      "  5.73586819e-06 1.87994586e-04 3.82820097e-04 5.31232242e-05\n",
      "  1.46582986e-03 3.35541361e-04 1.29100277e-04 1.02522738e-03\n",
      "  8.87480872e-03 4.79001636e-04 1.50841052e-06 8.66472204e-05\n",
      "  9.75190168e-03 2.34542462e-03 3.25647161e-03 1.23243978e-03\n",
      "  1.23346487e-03 2.53201456e-04 5.70022510e-03 5.94239201e-06\n",
      "  1.31079731e-05 1.08411269e-03 1.32989684e-03 1.87394968e-03\n",
      "  2.25530735e-03 2.11696339e-04 2.69262076e-04 1.36627805e-04\n",
      "  3.86783956e-05 5.13613986e-05 1.22646244e-03 3.56183106e-03\n",
      "  1.29784248e-03 7.06119821e-05 1.97535682e-04 1.19724791e-03\n",
      "  1.77868770e-03 1.13243925e-03 1.10518785e-04 8.96905591e-05\n",
      "  4.22750552e-04 5.50266594e-07 6.88961126e-05 4.87128021e-04\n",
      "  1.21362386e-04 1.47366276e-04 1.88627246e-04 2.77989508e-04\n",
      "  2.12926012e-03 3.25585509e-04 5.41352285e-04 8.95688697e-04\n",
      "  8.19052549e-05 1.08625097e-04 8.43017988e-03 3.88709718e-04\n",
      "  9.13869841e-04 1.15711415e-03 3.69651054e-04 1.13662951e-03\n",
      "  1.26215614e-03 4.10033412e-03 6.04520362e-03 2.38024513e-03\n",
      "  4.64602301e-03 1.85513714e-03 3.50448449e-03 2.08920529e-04\n",
      "  1.89944679e-04 1.29627071e-03 3.85979774e-04 7.76021505e-04\n",
      "  3.26471750e-04 2.01181714e-03 4.72930753e-04 1.80342557e-04\n",
      "  2.14881435e-03 6.22407327e-05 1.00882084e-03 3.02814325e-04\n",
      "  3.08899553e-05 1.65824749e-03 7.45459961e-08 7.12866165e-04\n",
      "  3.90648373e-04 3.95862468e-05 1.09302339e-03 1.74124247e-03\n",
      "  1.49877675e-04 5.81849422e-04 3.31410036e-04 2.91426577e-05\n",
      "  4.02240747e-04 5.51430337e-05 7.37903774e-05 4.39769189e-03\n",
      "  8.61324269e-05 2.32220543e-04 3.19964333e-03 2.15593493e-03\n",
      "  3.43519941e-03 4.42477291e-05 1.97304296e-03 1.14707954e-03\n",
      "  8.01067547e-04 3.15030434e-04 1.55640524e-03 2.29893532e-04\n",
      "  1.53046685e-03 1.90871250e-04 3.61024937e-04 1.03778947e-04\n",
      "  2.97219566e-03 4.18886780e-05 3.84295328e-04 3.85206731e-04\n",
      "  2.03658917e-04 1.42713758e-03 1.45724911e-03 5.70734361e-04\n",
      "  6.08482328e-04 1.07654003e-04 7.22434339e-04 1.99483357e-04\n",
      "  3.32560453e-08 1.90280493e-04 2.29860355e-03 1.62940716e-04\n",
      "  9.67700640e-05 3.24818863e-03 1.19880227e-03 1.09609319e-03\n",
      "  5.30567493e-05 3.80886713e-03 5.45885571e-03 3.10595738e-03\n",
      "  5.54997142e-04 4.95951181e-03 4.51400945e-05 2.40370906e-03\n",
      "  1.41612639e-03 2.48731055e-04 8.19651204e-05 4.23058199e-05\n",
      "  2.11621159e-03 1.86632012e-06 5.82645719e-03 4.14978249e-05\n",
      "  1.42150012e-03 2.89058783e-03 3.80655452e-03 5.32421652e-05\n",
      "  5.91776096e-04 3.06765551e-05 3.05573305e-05 2.88191211e-05\n",
      "  3.31593654e-04 2.66542833e-03 3.51387260e-03 2.89962062e-03\n",
      "  5.95361947e-04 3.50474134e-06 1.79959841e-03 9.71327754e-03\n",
      "  1.99395122e-04 3.14754029e-04 3.28729997e-04 1.25531649e-03\n",
      "  2.14536379e-03 4.58570879e-05 3.48920402e-04 7.98236392e-03\n",
      "  1.06161527e-02 1.63937082e-04 3.09081791e-03 4.02825684e-04\n",
      "  5.82441180e-05 6.70188104e-04 1.51934126e-03 2.57777726e-04\n",
      "  5.32893992e-06 9.43396366e-04 2.48995209e-04 3.68017257e-04\n",
      "  2.23244659e-03 2.49588135e-09 6.76866559e-03 7.26045250e-06\n",
      "  3.42581753e-04 1.42127016e-04 2.78519734e-03 6.10641467e-03\n",
      "  6.57305052e-04 3.11839069e-04 1.87727595e-03 2.05203902e-04\n",
      "  7.10983802e-03 1.26540070e-03 1.11469473e-04 1.44804139e-03\n",
      "  8.15481264e-05 1.95052889e-04 3.98045579e-03 1.93105784e-04\n",
      "  3.62673898e-04 8.64053694e-05 6.76218919e-04 4.99047599e-04\n",
      "  1.19753159e-02 5.38924589e-03 4.83076741e-04 1.27901915e-03\n",
      "  1.18114685e-05 3.80430324e-04 4.51225582e-04 2.20905181e-05\n",
      "  9.00833698e-06 2.61656845e-04 2.14485941e-03 3.65103774e-03\n",
      "  3.89940978e-04 7.05458116e-05 4.18801362e-04 5.95432143e-04\n",
      "  4.91738148e-04 3.01816233e-03 7.14280316e-05 5.40359939e-04\n",
      "  4.52515950e-05 1.49618784e-04 5.29808470e-04 2.53535833e-03\n",
      "  3.59436705e-04 2.58233407e-03 5.32681965e-05 8.54359217e-04\n",
      "  7.06284170e-03 1.38573865e-04 2.83179800e-03 9.97424803e-04\n",
      "  6.25917555e-03 7.84002406e-04 9.11934467e-04 5.90225134e-04\n",
      "  8.07963389e-04 8.57350309e-04 2.06644165e-03 4.37342661e-04\n",
      "  4.86951249e-06 7.93845811e-06 1.12977374e-05 1.27745618e-04\n",
      "  1.67422951e-04 1.13836925e-03 1.13886174e-05 2.40885905e-03\n",
      "  4.34848054e-03 1.60509617e-05 8.03328602e-04 2.41903935e-04\n",
      "  1.15100446e-04 1.47970172e-03 1.12012934e-03 1.14678019e-04\n",
      "  1.07299721e-03 6.71698302e-05 1.16061773e-03 9.37498464e-06\n",
      "  1.85878697e-03 9.19134000e-04 1.05846197e-03 1.44785376e-03\n",
      "  5.73146090e-03 9.37248242e-04 1.48059370e-03 1.99413359e-03\n",
      "  1.35797260e-03 3.44769378e-06 3.45407569e-03 1.96545245e-03\n",
      "  1.50289392e-04 3.16173006e-03 2.50854746e-03 4.05871958e-03\n",
      "  1.01620366e-03 3.57107919e-03 1.23376617e-03 1.09798092e-05\n",
      "  6.31242385e-04 4.05693041e-04 1.41333766e-02 1.60344041e-03\n",
      "  2.63450673e-03 4.27877680e-04 3.90424743e-03 1.14236503e-03\n",
      "  7.46069792e-04 1.07382060e-06 6.17121469e-04 5.94401231e-05\n",
      "  6.97007871e-05 1.45352673e-04 1.56531133e-03 1.86212102e-05\n",
      "  4.51827187e-04 2.53573688e-04 4.46160602e-04 2.10223528e-03\n",
      "  6.44127355e-04 2.28448942e-04 2.57783783e-05 1.03453106e-03\n",
      "  4.28117264e-03 1.46728656e-04 1.89887495e-05 2.93991045e-04\n",
      "  1.19086029e-04 2.52132849e-03 3.36466054e-03 6.05542580e-03\n",
      "  7.90690578e-03 2.04211615e-03 3.92305858e-03 1.20289155e-03\n",
      "  2.62750746e-04 1.09065730e-03 1.09013426e-06 1.78128943e-05\n",
      "  1.19177989e-04 3.31329591e-04 2.85689728e-06 3.73405570e-04\n",
      "  5.47265975e-03 3.96619405e-04 2.66398499e-04 1.12726103e-06\n",
      "  1.05222891e-04 1.21065194e-03 3.34174990e-03 4.63889186e-04\n",
      "  1.10116271e-04 1.23028598e-04 3.88150908e-03 9.31557527e-05\n",
      "  2.23023131e-04 1.69436527e-04 4.37073986e-05 7.91154001e-03\n",
      "  1.72034088e-03 1.17763861e-04 5.70894181e-04 1.66436885e-03\n",
      "  9.64818007e-04 8.55094613e-05 8.46845036e-05 1.91998329e-04\n",
      "  1.88055121e-05 2.95354215e-03 8.40982514e-04 2.75436552e-06\n",
      "  6.80922329e-04 3.47560590e-04 3.64711085e-04 2.27648458e-03\n",
      "  1.91149607e-03 6.59965063e-04 3.30547169e-04 2.82695982e-04\n",
      "  3.31392450e-03 2.73052269e-03 1.72405625e-04 1.01527899e-03\n",
      "  6.22872248e-04 1.04177755e-03 4.45107236e-03 5.66037007e-04\n",
      "  1.74336101e-05 1.41790955e-04 1.07968241e-03 1.20772638e-04\n",
      "  8.19963624e-04 3.87803476e-04 2.89224473e-04 4.22562364e-03\n",
      "  3.21620394e-04 1.87376266e-05 1.04432589e-03 1.77270745e-05\n",
      "  6.98642159e-04 7.33988746e-08 2.55082970e-04 2.46868344e-03\n",
      "  1.27727271e-04 2.28837012e-04 1.95352735e-05 1.04709173e-04\n",
      "  1.73818595e-06 9.32013042e-04 1.75698815e-04 3.72035365e-03\n",
      "  6.84408140e-04 4.32946414e-03 3.58303893e-03 1.42341526e-04\n",
      "  5.06878686e-03 4.74738783e-04 1.69272096e-03 8.73434870e-04\n",
      "  2.30463757e-03 1.08540362e-08 2.56866606e-05 1.95583783e-04\n",
      "  1.09186875e-05 1.19399028e-03 1.34963317e-03 1.16530442e-04\n",
      "  7.95786636e-04 5.35689279e-05 6.69570098e-04 5.87702045e-04\n",
      "  6.37340657e-04 9.90046740e-04 2.85662627e-04 5.43822404e-04\n",
      "  4.91758926e-05 1.46906418e-03 7.45565774e-04 4.04479428e-05\n",
      "  8.37217925e-05 1.61662975e-07 5.52424914e-04 2.99139880e-05\n",
      "  6.93301641e-04 1.90433935e-03 1.21068190e-05 1.12032344e-03\n",
      "  5.28763794e-05 2.28048283e-03 5.27871327e-03 3.17922785e-04\n",
      "  2.79339898e-05 3.80294877e-04 9.12843696e-05 9.05084931e-04\n",
      "  5.09892614e-03 3.30669508e-04 5.74004733e-04 7.15353813e-04\n",
      "  5.32470944e-04 1.44664175e-04 3.94505833e-03 2.54118746e-03\n",
      "  2.05602216e-03 5.76393813e-05 5.83393087e-03 3.86810093e-05\n",
      "  3.57461517e-06 7.55971243e-04 1.79380605e-04 4.27994238e-06\n",
      "  8.93292214e-04 3.31403254e-05 6.27770246e-04 8.17907360e-06\n",
      "  1.15670528e-04 1.62689129e-04 4.77140413e-03 6.36828507e-04\n",
      "  9.09778753e-05 6.26256100e-03 1.07151442e-03 3.02122811e-03\n",
      "  6.80613231e-04 2.48270744e-03 4.85738003e-04 5.69149322e-04\n",
      "  7.52365059e-04 2.62368640e-03 1.27869722e-03 1.57697357e-03\n",
      "  1.51884758e-03 1.19226927e-03 8.56726282e-03 1.37579980e-04\n",
      "  3.45658489e-03 8.02192141e-03 6.20389216e-04 7.25789998e-03\n",
      "  4.92043452e-04 5.36100761e-03 1.23007198e-03 8.46546182e-04\n",
      "  9.74530440e-04 2.19652046e-03 1.94703156e-05 9.28886649e-06\n",
      "  2.39643375e-04 2.52035647e-04 3.57935905e-04 1.12672062e-02\n",
      "  6.22679078e-04 6.08125006e-04 3.20722373e-05 2.96739171e-04\n",
      "  3.08677112e-03 6.97556163e-04 1.19556456e-03 3.11283908e-03\n",
      "  6.41067219e-04 6.48369864e-03 1.11176023e-03 5.59329443e-04\n",
      "  2.91658488e-03 7.03905002e-06 6.11087673e-08 1.26435798e-04\n",
      "  3.43037006e-04 7.77529408e-03 4.02852269e-07 9.19288324e-04\n",
      "  3.16137647e-03 1.77309232e-04 1.41902308e-03 5.39864847e-04\n",
      "  3.95485080e-04 7.06090858e-03 9.12696824e-04 1.33933394e-03\n",
      "  3.50197562e-06 1.74630699e-03 8.92004793e-04 1.19181302e-02]]\n",
      "Zeeta\n",
      "Doc_0\n",
      "[[1 1 0 ... 0 1 0]\n",
      " [1 1 0 ... 0 1 0]]\n",
      "Doc_1\n",
      "[[0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Theta mean:\")\n",
    "for item in theta_mean:\n",
    "    print(item)\n",
    "    \n",
    "print(\"Phi mean:\")\n",
    "for item in phi_mean:\n",
    "    print(item)\n",
    "    \n",
    "print(\"Zeeta\")\n",
    "LDA.print_zeeta(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Can the topic model be used to define a topic-based similarity measure between documents?**\n",
    "\n",
    "In order to mesaure the topic-based similarity between two documents, we have to measure the difference between their probability distributions. For this, we can use an f-divergence. Many common divergences, such as KL-Divergence, Hellinger distance and total variation distance are special cases of f-divergence, coinciding with a particular choice of f.\n",
    "\n",
    "More info can be found here: https://en.wikipedia.org/wiki/F-divergence\n",
    "\n",
    "I chose the Hellinger distance, as it seems to be the most popular one. https://en.wikipedia.org/wiki/Hellinger_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_Hellinger_distance(LDA):\n",
    "    hell_matrix = np.zeros((LDA.M, LDA.M))\n",
    "    \n",
    "    topic_docs = []\n",
    "    for doc in range(LDA.M):\n",
    "        topic_docs.append(LDA.mcmc.trace('theta_%i' % doc)[:].mean(axis=0))\n",
    "        \n",
    "    for i in range(LDA.M):\n",
    "        for j in range(LDA.M):\n",
    "            hell_matrix[i][j] = (1 / np.sqrt(2)) * np.sqrt(np.sum((np.sqrt(topic_docs[i]) - np.sqrt(topic_docs[j])) ** 2))\n",
    "    \n",
    "    ax = sns.heatmap(hell_matrix, annot=True, linewidths=1).set_title(\"Hellinger distance between documents\")\n",
    "    \n",
    "    print(hell_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.11723156]\n",
      " [0.11723156 0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_Hellinger_distance(LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What about new documents? How can topics be assigned to it?**\n",
    "\n",
    "The easiest way to add new documents and assing topics to add the new document to the document\n",
    "list and run inference on them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [-----------------100%-----------------] 2000 of 2000 complete in 63.1 sec"
     ]
    }
   ],
   "source": [
    "docs.append(new_doc)\n",
    "LDA.initialize_vocabulary(docs)\n",
    "LDA.mcmc.sample(2000, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions**\n",
    "\n",
    "Works well on sanity check and on the examples in the course.\n",
    "\n",
    "As for the text from wikipedia, seeing that it takes too much time to run, I only took the first 1000 words of each wikipedia page content. The results in similarity seem legit, but it is impossible to draw a real conclusion. For this, extensive testing should be done on multiple pages with more content on each.\n",
    "\n",
    "As for text pre-processing, although it can help, it is important to pay careful attention to the text before and after it was preprocessed. Minimal preprocessing is probably the safe way to go (removing stopwords, pnctuation etc), but stemming and lemmatizing should be done carefully. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
