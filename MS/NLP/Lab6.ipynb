{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/irikos/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/irikos/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "import numpy as np\n",
    "from nltk.wsd import lesk\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it has some errors, doesn't work\n",
    "\n",
    "def wikipedia_disambiguation(page_title):\n",
    "    disambiguation = [page_title]\n",
    "    #create a connection(session)\n",
    "    r_session = requests.Session()\n",
    "\n",
    "    #url for the MediaWiki action API\n",
    "    URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "    PARAMS = {\n",
    "        \"action\": \"query\", #we are creating a query\n",
    "        \"titles\": \"soda\", #for the title car    \n",
    "        \"prop\": \"redirects\", #asking for all the redirects (to the title car)\n",
    "        \"format\": \"json\" #and we want the output in a json format\n",
    "    }\n",
    "\n",
    "    #we obtain the response to the get request with the given parmeters\n",
    "    query_response = r_session.get(url=URL, params=PARAMS)\n",
    "    json_data = query_response.json()\n",
    "    print()\n",
    "    wikipedia_pages = json_data[\"query\"][\"pages\"]\n",
    "    #we iterate through items and print all the redirects (their title and id)\n",
    "    try:\n",
    "        for k, v in wikipedia_pages.items():\n",
    "            for redir in v[\"redirects\"]:\n",
    "                print(\"{} redirect to {}({})\".format(redir[\"title\"], v[\"title\"], redir[\"pageid\"]))\n",
    "                disambiguation.append(v[\"title\"])\n",
    "                pageid = redir[\"pageid\"]\n",
    "                PARAMS2 = {\n",
    "                    \"action\": \"query\", #we are creating a query    \n",
    "                    \"prop\": \"info\", #asking for all the redirects (to the title car)\n",
    "                    \"format\": \"json\", #and we want the output in a json format\n",
    "                    \"pageids\": pageid\n",
    "                }\n",
    "                query_response2 = r_session.get(url=URL, params=PARAMS2)\n",
    "                json_data2 = query_response2.json()\n",
    "                wiki = json_data2[\"query\"][\"pages\"]\n",
    "#                 print(wiki)\n",
    "#                 print(query_response.json[\"query\"][\"pages\"][pageid][\"title\"])\n",
    "            \n",
    "    except KeyError as err:\n",
    "        if err.args[0]=='redirects':\n",
    "            print(\"It has no redirects\")\n",
    "        else:\n",
    "            print(repr(err))\n",
    "            \n",
    "    # I know it's a stupid way to do it, but couldn't find fast how to include many prop\n",
    "    PARAMS = {\n",
    "        \"action\": \"query\", #we are creating a query\n",
    "        \"titles\": \"soda\", #for the title car    \n",
    "        \"prop\": \"categories\", #asking for all the redirects (to the title car)\n",
    "        \"format\": \"json\" #and we want the output in a json format\n",
    "    }\n",
    "\n",
    "    #we obtain the response to the get request with the given parmeters\n",
    "    query_response = r_session.get(url=URL, params=PARAMS)\n",
    "    json_data = query_response.json()\n",
    "    wikipedia_pages = json_data[\"query\"][\"pages\"]\n",
    "    #we iterate through items and print all the redirects (their title and id)\n",
    "    try:\n",
    "        for k, v in wikipedia_pages.items():\n",
    "            for cat in v['categories']:\n",
    "                print(cat[\"title\"]) ##### HOW DO YOU GET THE SYNTACTIC HEAD???\n",
    "                disambiguation.append(cat['title'])\n",
    "                   \n",
    "            \n",
    "    except KeyError as err:\n",
    "        if err.args[0]=='redirects':\n",
    "            print(\"It has no redirects\")\n",
    "        else:\n",
    "            print(repr(err))\n",
    "            \n",
    "    \n",
    "    \n",
    "    print(disambiguation)\n",
    "    return disambiguation\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SODA redirect to Soda(3318069)\n",
      "Sodas redirect to Soda(5599353)\n",
      "Soday redirect to Soda(13752636)\n",
      "Soda (disambiguation) redirect to Soda(19677220)\n",
      "Soda drink redirect to Soda(47486780)\n",
      "Category:All article disambiguation pages\n",
      "Category:All disambiguation pages\n",
      "Category:Articles containing Japanese-language text\n",
      "Category:Disambiguation pages\n",
      "Category:Disambiguation pages with short descriptions\n",
      "Category:Disambiguation pages with surname-holder lists\n",
      "Category:Japanese-language surnames\n",
      "['soda', 'Soda', 'Soda', 'Soda', 'Soda', 'Soda', 'Category:All article disambiguation pages', 'Category:All disambiguation pages', 'Category:Articles containing Japanese-language text', 'Category:Disambiguation pages', 'Category:Disambiguation pages with short descriptions', 'Category:Disambiguation pages with surname-holder lists', 'Category:Japanese-language surnames']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['soda',\n",
       " 'Soda',\n",
       " 'Soda',\n",
       " 'Soda',\n",
       " 'Soda',\n",
       " 'Soda',\n",
       " 'Category:All article disambiguation pages',\n",
       " 'Category:All disambiguation pages',\n",
       " 'Category:Articles containing Japanese-language text',\n",
       " 'Category:Disambiguation pages',\n",
       " 'Category:Disambiguation pages with short descriptions',\n",
       " 'Category:Disambiguation pages with surname-holder lists',\n",
       " 'Category:Japanese-language surnames']"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia_disambiguation(\"soda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(sentence):\n",
    "    sentence_split = nltk.word_tokenize(sentence.lower())    \n",
    "    only_words = [word.lower() for word in sentence_split if word.isalnum()]\n",
    "    relevant_words = [word for word in only_words if word not in stopwords.words('english')]\n",
    "    lemmatized = [wnl.lemmatize(word) for word in relevant_words]\n",
    "    return lemmatized\n",
    "\n",
    "def wordnet_disambiguation(word, part_of_speech, number): # part_of_speech = \"n\" / \"v\" etc. No is 1 2 etc etc\n",
    "    disambiguation = []\n",
    "    synset = \"\"\n",
    "    # get the synset\n",
    "    for ss in wordnet.synsets(word):\n",
    "        if (ss.pos().lower() == part_of_speech):\n",
    "            synset = ss\n",
    "            \n",
    "    # add its synonyms\n",
    "    disambiguation += synset.lemma_names()\n",
    "    \n",
    "    # add the hypernyms and hyponyms\n",
    "    for hyp in synset.hypernyms():\n",
    "        disambiguation.append(hyp.name().split('.')[0])\n",
    "        print(hyp.root_hypernyms())\n",
    "#         print(dir(hyp))\n",
    "        \n",
    "    for hyp in synset.hyponyms():\n",
    "        disambiguation.append(hyp.name().split('.')[0])        \n",
    "    # add the gloss, keeping only the lemmatized content words\n",
    "    disambiguation += get_context(synset.definition())\n",
    "    \n",
    "    # systerhood?\n",
    "    disambiguation += synset.similar_tos()\n",
    "    print (disambiguation)\n",
    "    \n",
    "def return_all(synset):\n",
    "    syn_all = \"\"\n",
    "    for hyp in synset.hypernyms():\n",
    "        syn_all += \" \" + hyp.definition().lower()\n",
    "    for hyp in synset.hyponyms():\n",
    "        syn_all += \" \" + hyp.definition().lower()\n",
    "    for hyp in synset.part_meronyms():\n",
    "        syn_all += \" \" + hyp.definition().lower()\n",
    "    for hyp in synset.substance_meronyms():\n",
    "        syn_all += \" \" + hyp.definition().lower()\n",
    "    for hyp in synset.member_meronyms():\n",
    "        syn_all += \" \" + hyp.definition().lower()\n",
    "    for hyp in synset.similar_tos():\n",
    "        syn_all += \" \" + hyp.definition().lower()\n",
    "    for hyp in synset.also_sees():\n",
    "        syn_all += \" \" + hyp.definition().lower()\n",
    "    return syn_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('entity.n.01')]\n",
      "['pop', 'soda', 'soda_pop', 'soda_water', 'tonic', 'soft_drink', 'sweet', 'drink', 'containing', 'carbonated', 'water', 'flavoring']\n",
      "\n",
      "SODA redirect to Soda(3318069)\n",
      "Sodas redirect to Soda(5599353)\n",
      "Soday redirect to Soda(13752636)\n",
      "Soda (disambiguation) redirect to Soda(19677220)\n",
      "Soda drink redirect to Soda(47486780)\n",
      "Category:All article disambiguation pages\n",
      "Category:All disambiguation pages\n",
      "Category:Articles containing Japanese-language text\n",
      "Category:Disambiguation pages\n",
      "Category:Disambiguation pages with short descriptions\n",
      "Category:Disambiguation pages with surname-holder lists\n",
      "Category:Japanese-language surnames\n",
      "['soda', 'Soda', 'Soda', 'Soda', 'Soda', 'Soda', 'Category:All article disambiguation pages', 'Category:All disambiguation pages', 'Category:Articles containing Japanese-language text', 'Category:Disambiguation pages', 'Category:Disambiguation pages with short descriptions', 'Category:Disambiguation pages with surname-holder lists', 'Category:Japanese-language surnames']\n"
     ]
    }
   ],
   "source": [
    "wordnet_sense = wordnet_disambiguation(\"soda\", \"n\", \"1\")\n",
    "wikipedia_senses = wikipedia_disambiguation(\"soda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-396-60b3a4385edb>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-396-60b3a4385edb>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    if\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def mapping_algorithm(wikipedia_sense, wordnet_senses):\n",
    "    mapping = []\n",
    "    for w in wikipedia_senses:\n",
    "        ### Who is epsilon here??\n",
    "        print(\"not sure who is epsilon to add it to the mapping\")\n",
    "    for w in wikipedia_senses:\n",
    "        if \n",
    "        \n",
    "        \n",
    "##### Algorithm from the paper. I tried understanding it, but couldn't manage. \n",
    "# I understood a bit of it, but too much doesn't really make sense (ha, pun intended)\n",
    "Input: SensesWiki, SensesWN\n",
    "Output: a mapping µ : SensesWiki → SensesWN\n",
    "1: for each w ∈ SensesWiki\n",
    "2: µ(w) := \u000f\n",
    "3: for each w ∈ SensesWiki\n",
    "4: if |SensesWiki(w)| = |SensesWN(w)| = 1 then\n",
    "5: µ(w) := w\n",
    "1\n",
    "n\n",
    "6: for each w ∈ SensesWiki\n",
    "7: if µ(w) = \u000f then\n",
    "8: for each d ∈ SensesWiki s.t. d redirects to w\n",
    "9: if µ(d) 6= \u000f and µ(d) is in a synset of w then\n",
    "10: µ(w) := sense of w in synset of µ(d); break\n",
    "11: for each w ∈ SensesWiki\n",
    "12: if µ(w) = \u000f then\n",
    "13: if no tie occurs then\n",
    "14: µ(w) := argmax\n",
    "s∈SensesWN(w)\n",
    "p(s|w)\n",
    "15: return µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
