{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Vision\n",
    "### Lab 7\n",
    "#### Project 2  - Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import uniform\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-maxima suppresion for detecting snooker balls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Malisiewicz et al.\n",
    "# non-maxima suppresion: remove all the bounding boxes considered as detections\n",
    "# if they overlap with a higher scored bounding box\n",
    "# each box has format [xmin, ymin, xmax, ymax, score]\n",
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "\n",
    "    # initialize the list of picked indexes\t\n",
    "    pick = []\n",
    "\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "    scores = boxes[:, 4]\n",
    "    \n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(scores)\n",
    "\n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        # find the largest (x, y) coordinates for the start of\n",
    "        # the bounding box and the smallest (x, y) coordinates\n",
    "        # for the end of the bounding box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        \n",
    "        # delete all indexes from the index list that have higher overlap\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "\n",
    "    # return only the bounding boxes that were picked    \n",
    "    return boxes[pick]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "template_matching/yellow.jpg (18, 19, 3)\n",
      "template_matching/brown.jpg (18, 16, 3)\n",
      "template_matching/blue.jpg (18, 16, 3)\n",
      "template_matching/black.jpg (23, 23, 3)\n",
      "template_matching/green.jpg (16, 15, 3)\n",
      "template_matching/white.jpg (25, 27, 3)\n",
      "template_matching/pink.jpg (22, 21, 3)\n",
      "template_matching/red.jpg (19, 16, 3)\n"
     ]
    }
   ],
   "source": [
    "# read the templates balls\n",
    "templates = []\n",
    "base_folder_matching = 'template_matching'\n",
    "images_names = glob.glob(os.path.join(base_folder_matching, \"*.jpg\")) \n",
    "for image_name in images_names:      \n",
    "    template = cv.imread(image_name) \n",
    "    templates.append(template) \n",
    "    print(image_name,template.shape)\n",
    "    cv.imshow(\"template\", template)\n",
    "    cv.waitKey(2000)\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "color_dict = {0: \"black\",\n",
    "              1: \"blue\",\n",
    "              2: \"brown\",\n",
    "              3: \"green\",\n",
    "              4: \"pink\",\n",
    "              5: \"red\",\n",
    "              6: \"white\",\n",
    "              7: \"yellow\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the first frame from a video\n",
    "video_path = os.path.join('videos_table', \"4_table.mp4\")\n",
    "\n",
    "cap = cv.VideoCapture(video_path)\n",
    "assert cap.isOpened() is True\n",
    "\n",
    "ret, first_frame = cap.read()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of initial detections 24\n",
      "After NMS detections 2\n",
      "black\n",
      "Number of initial detections 33\n",
      "After NMS detections 4\n",
      "blue\n",
      "Number of initial detections 15\n",
      "After NMS detections 4\n",
      "brown\n",
      "Number of initial detections 2\n",
      "After NMS detections 1\n",
      "green\n",
      "Number of initial detections 19\n",
      "After NMS detections 3\n",
      "pink\n",
      "Number of initial detections 90\n",
      "After NMS detections 4\n",
      "red\n",
      "Number of initial detections 51\n",
      "After NMS detections 4\n",
      "white\n",
      "Number of initial detections 24\n",
      "After NMS detections 5\n",
      "yellow\n"
     ]
    }
   ],
   "source": [
    "# run template matching using a threshold\n",
    "frame = first_frame.copy() \n",
    "idx = -1\n",
    "for template in templates:    \n",
    "    idx = idx + 1\n",
    "    template_gray = cv.cvtColor(template, cv.COLOR_BGR2GRAY)    \n",
    "    w, h = template_gray.shape[::-1]\n",
    "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    res = cv.matchTemplate(frame_gray, template_gray, cv.TM_CCOEFF_NORMED)\n",
    "    \n",
    "    cv.imshow(\"Map\", res)\n",
    "    threshold = 0.75\n",
    "    loc = np.where( res >= threshold)\n",
    "    frame_draw = first_frame.copy() \n",
    "    for pt in zip(*loc[::-1]):\n",
    "        cv.rectangle(frame_draw, pt, (pt[0] + w, pt[1] + h), (0,0,255), 1)\n",
    "    \n",
    "    cv.imshow(\"Template_matching \" + color_dict[idx], frame_draw)\n",
    "    boxes = np.float32(np.zeros((len(loc[0]),5)))\n",
    "    for i in range(len(loc[0])):\n",
    "        boxes[i,0] = loc[1][i]\n",
    "        boxes[i,1] = loc[0][i]\n",
    "        boxes[i,2] = loc[1][i] + w - 1\n",
    "        boxes[i,3] = loc[0][i] + h - 1\n",
    "        boxes[i,4] = res[loc[0][i],loc[1][i]]\n",
    "    overlapThresh = 0.4\n",
    "    bb = non_max_suppression_fast(boxes, overlapThresh)\n",
    "    print(\"Number of initial detections\", boxes.shape[0])\n",
    "    print(\"After NMS detections\", bb.shape[0])\n",
    "    frame_draw_2 = first_frame.copy()\n",
    "    for i in range(len(bb)):\n",
    "        cv.rectangle(frame_draw_2, (bb[i,0], bb[i,1]), (bb[i,2], bb[i,3]), (0,0,255), 1)\n",
    "    \n",
    "    print(color_dict[idx])\n",
    "    cv.imshow(\"Template_matching \" + color_dict[idx] + \"_nms\", frame_draw_2)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background subtraction using frame difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do frame difference\n",
    "# change the path to match on your machine\n",
    "base_folder = 'videos'\n",
    "path_video = os.path.join(base_folder, \"8.mp4\")\n",
    "\n",
    "cap = cv.VideoCapture(path_video)  \n",
    "current_frame = 0\n",
    "max_number_of_frame_to_run = 750\n",
    "\n",
    "ret, frame = cap.read() # Read the frame\n",
    "frame_gray = cv.cvtColor(frame,cv.COLOR_BGR2GRAY)\n",
    "old_frame_gray = frame_gray\n",
    "\n",
    "while(cap.isOpened()): \n",
    "    ret, frame = cap.read() # Read the frame\n",
    "    if ret is True: \n",
    "        current_frame = current_frame + 1 \n",
    "        frame_gray = cv.cvtColor(frame,cv.COLOR_BGR2GRAY)\n",
    "                    \n",
    "        # compute frame diff            \n",
    "        temp_1 = np.float16(frame_gray) - np.float16(old_frame_gray)           \n",
    "        temp_2 = np.abs(temp_1)\n",
    "        diff_frame = np.uint8(temp_2)\n",
    "        \n",
    "        cv.imshow(\"Frame diff\",diff_frame)\n",
    "        \n",
    "        old_frame_gray = frame_gray\n",
    "        \n",
    "        if current_frame > max_number_of_frame_to_run:\n",
    "            break\n",
    "            \n",
    "        if cv.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# after playing the video, release the video capture    \n",
    "cap.release()\n",
    "# close all the frames\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particle filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a particle is a bounding box, represented by the top left corner \n",
    "# and fixed width and hieght\n",
    "def create_uniform_particles(x_range, y_range, N):\n",
    "    particles = np.empty((N, 2))\n",
    "    particles[:, 0] = uniform(x_range[0], x_range[1], size=N)\n",
    "    particles[:, 1] = uniform(y_range[0], y_range[1], size=N) \n",
    "    return particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict where the particles will be at the nex frame by applying some dynamics\n",
    "# take into account velocity and some random noise\n",
    "\n",
    "def predict(particles, velocity, std, frame, w, h):\n",
    "    \n",
    "    N = len(particles)    \n",
    "    \n",
    "    noise = np.random.randn(N) * std[0]  \n",
    "    for i in range(N):\n",
    "        particles[i, 0] = particles[i, 0] + velocity[0] + noise[i]\n",
    "        # check that the particle is not outside of the image\n",
    "        if(particles[i, 0] > frame.shape[1] -w):\n",
    "            particles[i, 0] = frame.shape[1] - w\n",
    "        if(particles[i, 0] < 0):\n",
    "            particles[i, 0] = 0\n",
    "            \n",
    "    noise = np.random.randn(N) * std[1]\n",
    "    for i in range(N):\n",
    "        particles[i, 1] = particles[i, 1] + velocity[1] + noise[i]\n",
    "        if(particles[i, 1] > frame.shape[0] - h):\n",
    "            particles[i, 1] = frame.shape[0] - h\n",
    "        if(particles[i, 1] < 0):\n",
    "            particles[i, 1] = 0 \n",
    "    return particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the weight of each particle based on how similar is to the target window\n",
    "# use a simple color histogram model\n",
    "# essential step: how to update the weights\n",
    "def update(particles, frame, hist_roi_norm, w, h):\n",
    "    particles = np.int32(particles)   \n",
    "    weights = np.zeros((particles.shape[0],1))\n",
    "    for i in range(particles.shape[0]):\n",
    "        img_particle = frame[particles[i, 1]: particles[i, 1] + h - 1, particles[i, 0]:particles[i, 0] + w - 1].copy()\n",
    "        particle_hist = cv.calcHist([img_particle], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]) \n",
    "        particle_hist_norm = particle_hist/ particle_hist.sum()\n",
    "        distance = cv.compareHist(hist_roi_norm, particle_hist_norm, cv.HISTCMP_CHISQR_ALT)\n",
    "        # higher chi-square distance is bad, smaller chi-square distance is better\n",
    "        weights[i] = 1 / (distance)\n",
    "    weights += 1.e-10 # avoid round-off to zero\n",
    "    prints(weigths.min())\n",
    "    prints(weigths.max())\n",
    "    # normalize the wights such that we have a probability distribution\n",
    "    weights /= sum(weights)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the center of the cloud of particles\n",
    "def estimate(particles, weights):    \n",
    "    mean = np.float64(np.array([0,0]))\n",
    "    N = particles.shape[0]  \n",
    "    for i in range(N): \n",
    "        mean += weights[i] * particles[i, :]   \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample particles based on their weight\n",
    "def resample(weights):\n",
    "    w = weights.flatten()\n",
    "    N = len(w)    \n",
    "    tries = np.random.multinomial(N, w) \n",
    "    indexes = np.zeros(N, 'i')\n",
    "    cumsum_vector = np.cumsum(tries)\n",
    "    pos = -1 \n",
    "    for i in range(len(tries)):\n",
    "        for j in range(tries[i]):            \n",
    "            pos = pos + 1\n",
    "            indexes[pos] = i\n",
    "            \n",
    "    return indexes\n",
    "\n",
    "def resample_from_index(particles, weights, indexes):\n",
    "    particles[:] = particles[indexes]\n",
    "    weights[:] = weights[indexes]\n",
    "    weights /= np.sum(weights)\n",
    "    return particles, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_uniform_particles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b57daf076ce9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mparticles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_uniform_particles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mvelocity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_uniform_particles' is not defined"
     ]
    }
   ],
   "source": [
    "# change the path to match on your machine\n",
    "base_folder = 'videos'\n",
    "path_video = os.path.join(base_folder, \"11.mp4\")\n",
    "\n",
    "cap = cv.VideoCapture(path_video)  \n",
    "current_frame = 0\n",
    "max_number_of_frame_to_run = 750\n",
    "\n",
    "ret, frame = cap.read() # Read the frame\n",
    "frame_gray = cv.cvtColor(frame,cv.COLOR_BGR2GRAY)\n",
    "old_frame_gray = frame_gray\n",
    "\n",
    "ret, first_frame = cap.read() # Read the first frame         \n",
    "x, y, w, h = cv.selectROI(first_frame) \n",
    "img_roi = frame[y: y + h, x: x + w].copy()\n",
    "hist_roi = cv.calcHist([img_roi], [0 ,1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]) \n",
    "hist_roi_norm = hist_roi/ hist_roi.sum()\n",
    "bb = np.array([x, y, x + w - 1, y + h - 1])\n",
    "\n",
    "N = 1000\n",
    "particles = create_uniform_particles([x, x], [y, y], N)\n",
    "velocity = [0, 0]\n",
    "std = [25, 25] \n",
    "\n",
    "while(cap.isOpened()): \n",
    "    ret, frame = cap.read() # Read the frame   \n",
    "    if ret is True: \n",
    "        current_frame = current_frame + 1 \n",
    "        print(\"current_frame\", current_frame)\n",
    "        frame_gray = cv.cvtColor(frame,cv.COLOR_BGR2GRAY)\n",
    "                    \n",
    "        \n",
    "        particles = predict(particles, velocity, std, frame, w, h)        \n",
    "        \n",
    "        weights = update(particles, frame, hist_roi_norm, w, h) \n",
    "        \n",
    "        obj = np.int32(estimate(particles, weights))       \n",
    "       \n",
    "        velocity[0] = obj[0] - bb[0]\n",
    "        velocity[1] = obj[1] - bb[1]            \n",
    "        print('velocity = ', velocity)\n",
    "        bb = obj.copy()\n",
    "        \n",
    "        indexes = resample(weights)\n",
    "        particles, weights = resample_from_index(particles, weights, indexes)               \n",
    "        \n",
    "        for i in range(N):            \n",
    "            img2 = cv.rectangle(frame, (np.int32(particles[i,0]), np.int32(particles[i,1])), (np.int32(particles[i,0]) + w, np.int32(particles[i,1]) + h), (0,255,0), 1)\n",
    "        \n",
    "        img2 = cv.rectangle(frame, (obj[0], obj[1]), (obj[0] + w - 1, obj[1] + h - 1), (0, 255, 255), 4)\n",
    "        cv.imshow('img2', img2)   \n",
    "        cv.waitKey(100)\n",
    "        if current_frame > max_number_of_frame_to_run:\n",
    "            break\n",
    "            \n",
    "        if cv.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# after playing the video, release the video capture    \n",
    "cap.release()                \n",
    "# close all the frames\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
