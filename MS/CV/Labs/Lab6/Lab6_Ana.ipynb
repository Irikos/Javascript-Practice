{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Vision\n",
    "### Lab 6\n",
    "#### Project 2  - Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template matching for detecting the snooker balls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "template_matching/yellow.jpg (18, 19, 3)\n",
      "template_matching/brown.jpg (18, 16, 3)\n",
      "template_matching/blue.jpg (18, 16, 3)\n",
      "template_matching/black.jpg (23, 23, 3)\n",
      "template_matching/green.jpg (16, 15, 3)\n",
      "template_matching/white.jpg (25, 27, 3)\n",
      "template_matching/pink.jpg (22, 21, 3)\n",
      "template_matching/red.jpg (19, 16, 3)\n"
     ]
    }
   ],
   "source": [
    "# read the templates balls\n",
    "templates = []\n",
    "base_folder_matching = 'template_matching'\n",
    "images_names = glob.glob(os.path.join(base_folder_matching, \"*.jpg\")) \n",
    "for image_name in images_names:      \n",
    "    template = cv.imread(image_name) \n",
    "    templates.append(template) \n",
    "    print(image_name, template.shape)\n",
    "    cv.imshow(\"template\", template)\n",
    "    cv.waitKey(500)\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "color_dict = {0: \"black\",\n",
    "              1: \"blue\",\n",
    "              2: \"brown\",\n",
    "              3: \"green\",\n",
    "              4: \"pink\",\n",
    "              5: \"red\",\n",
    "              6: \"white\",\n",
    "              7: \"yellow\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the first frame from a video\n",
    "video_path = os.path.join('videos_table', \"3_table.mp4\")\n",
    "\n",
    "cap = cv.VideoCapture(video_path)\n",
    "assert cap.isOpened() is True\n",
    "\n",
    "ret, first_frame = cap.read()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run template matching using a threshold\n",
    "def get_matching_values(frame):\n",
    "    frame = first_frame.copy() \n",
    "    idx = -1\n",
    "    for template in templates:    \n",
    "        idx = idx + 1\n",
    "        template_gray = cv.cvtColor(template, cv.COLOR_BGR2GRAY)    \n",
    "        w, h = template_gray.shape[::-1]\n",
    "        frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        res = cv.matchTemplate(frame_gray, template_gray, cv.TM_CCOEFF_NORMED)\n",
    "\n",
    "        cv.imshow(\"Map\", res)\n",
    "        threshold = 0.75\n",
    "\n",
    "        loc = np.where( res >= threshold)\n",
    "        frame_draw = first_frame.copy() \n",
    "        boxes_number = 0\n",
    "        for pt in zip(*loc[::-1]):\n",
    "            boxes_number = boxes_number + 1\n",
    "            cv.rectangle(frame_draw, pt, (pt[0] + w, pt[1] + h), (0,0,255), 1)\n",
    "    return boxes_number\n",
    "        \n",
    "#     print(color_dict[idx])\n",
    "#     cv.imshow(\"Template_matching \" + color_dict[idx], frame_draw)\n",
    "#     cv.waitKey(0)\n",
    "#     cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED', 'cv.TM_CCORR', 'cv.TM_CCORR_NORMED', 'cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED']\n",
      "['cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED', 'cv.TM_CCORR', 'cv.TM_CCORR_NORMED', 'cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED']\n",
      "['cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED', 'cv.TM_CCORR', 'cv.TM_CCORR_NORMED', 'cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED']\n",
      "['cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED', 'cv.TM_CCORR', 'cv.TM_CCORR_NORMED', 'cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED']\n",
      "['cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED', 'cv.TM_CCORR', 'cv.TM_CCORR_NORMED', 'cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED']\n",
      "['cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED', 'cv.TM_CCORR', 'cv.TM_CCORR_NORMED', 'cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED']\n",
      "['cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED', 'cv.TM_CCORR', 'cv.TM_CCORR_NORMED', 'cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED']\n",
      "['cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED', 'cv.TM_CCORR', 'cv.TM_CCORR_NORMED', 'cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED']\n"
     ]
    }
   ],
   "source": [
    "# run template matching using different methods and min/max value\n",
    "frame = first_frame.copy()\n",
    "\n",
    "# All the 6 methods for comparison in a list\n",
    "methods = ['cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED','cv.TM_CCORR',\n",
    "            'cv.TM_CCORR_NORMED', 'cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED' ]\n",
    "\n",
    "# methods = ['cv.TM_CCOEFF_NORMED']\n",
    "\n",
    "idx = -1\n",
    "for template in templates:                \n",
    "    idx = idx + 1\n",
    "    template_gray = cv.cvtColor(template, cv.COLOR_BGR2GRAY)    \n",
    "    w, h = template_gray.shape[::-1]\n",
    "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    print(methods)\n",
    "    for meth in methods:        \n",
    "        method = eval(meth)\n",
    "        frame = first_frame.copy()\n",
    "        \n",
    "        # apply template Matching\n",
    "        res = cv.matchTemplate(frame_gray, template_gray,method)\n",
    "         \n",
    "        min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    "\n",
    "        # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "        if method in [cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]:\n",
    "            top_left = min_loc                      \n",
    "        else:\n",
    "            top_left = max_loc\n",
    "            \n",
    "        bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "\n",
    "        cv.rectangle(frame,top_left, bottom_right, 255, 2)\n",
    "        \n",
    "        cv.imshow(\"Template_matching \" + color_dict[idx] +' ' + meth, frame)\n",
    "        cv.waitKey(0)  \n",
    "        cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histrogram of colors for detecting the snooker balls color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a method to compute the histogram of a window in the quantized BGR color space\n",
    "def compute_hist(img, bins_0, bins_1 ,bins_2):\n",
    "    histogram = np.zeros((bins_0, bins_1, bins_2))\n",
    "    length_0 = 256 //  bins_0\n",
    "    length_1 = 256 // bins_1\n",
    "    length_2 = 256 // bins_2\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            pixel =  img[i][j] # color pixel with 3 channels\n",
    "            interval_0 = pixel[0] // length_0\n",
    "            interval_1 = pixel[1] // length_1\n",
    "            interval_2 = pixel[2] // length_2\n",
    "            histogram[interval_0, interval_1, interval_2] =  histogram[interval_0, interval_1, interval_2] + 1\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select ROI\n",
    "# frame = first_frame.copy()\n",
    "# x_min, y_min, w, h = cv.selectROI(frame)\n",
    "# x_max = x_min + w\n",
    "# y_max = y_min + h\n",
    "\n",
    "# # Crop image\n",
    "# img_crop = frame[y_min:y_max, x_min:x_max]\n",
    "\n",
    "# # Display cropped image \n",
    "# cv.imshow(\"Image\", img_crop)\n",
    "# cv.waitKey(0)\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compute the color histogram of the window in the quantized BGR color space\n",
    "# #u se our function\n",
    "# histogram_img = compute_hist(img_crop, 4, 4, 4)\n",
    "# print(histogram_img)\n",
    "# print(histogram_img.sum())\n",
    "# print(img_crop.shape[0] * img_crop.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compute the color histogram of the window in the quantized BGR color space\n",
    "# # use the function provided by OpenCV\n",
    "# hist_img = cv.calcHist([img_crop], [0, 1, 2], None, [4, 4, 4], [0, 256, 0, 256, 0, 256]) \n",
    "# print(hist_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we are going to compute the histograms for our templates\n",
    "hist_templates = []\n",
    "for template in templates:\n",
    "    template_hist = cv.calcHist([template], [0, 1, 2], None, [4, 4, 4], [0, 256, 0, 256, 0, 256])\n",
    "    hist_templates.append(template_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 22, 3)\n",
      "[2.324092660558912, 2.8168335414918095, 1.9623813127363814, 2.5457323597784645, 1.2155151758767695, 2.3547305323926286, 0.5276688653913233, 1.7372692943570462]\n",
      "white\n"
     ]
    }
   ],
   "source": [
    "# Select ROI\n",
    "frame = first_frame.copy()\n",
    "x_min, y_min, w, h = cv.selectROI(frame)\n",
    "x_max = x_min + w\n",
    "y_max = y_min + h\n",
    "\n",
    "# Crop image\n",
    "img_crop = frame[y_min:y_max, x_min:x_max]\n",
    "\n",
    "# Display cropped image \n",
    "cv.imshow(\"Image\", img_crop)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "print(img_crop.shape)\n",
    "\n",
    "hist_img = cv.calcHist([img_crop], [0, 1, 2], None, [4, 4, 4], [0, 256, 0, 256, 0, 256]) \n",
    "\n",
    "# do normalization for each histogram\n",
    "distances = []\n",
    "for i in range(len(templates)):\n",
    "    hist_img_norm = hist_img / (hist_img.sum())\n",
    "    hist_template_norm = hist_templates[i] / (hist_templates[i].sum())    \n",
    "    # use one of the possible distances between histograms - see function cv.compareHist\n",
    "    dist = cv.compareHist(hist_img_norm, hist_template_norm, cv.HISTCMP_CHISQR_ALT)\n",
    "    distances.append(dist)\n",
    "print(distances)\n",
    "print(color_dict[np.argmin(distances)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracking\n",
    "# change the path to match on your machine\n",
    "base_folder = 'videos'\n",
    "path_video1 = os.path.join(base_folder, \"3.mp4\")\n",
    "path_video2 = os.path.join(base_folder, \"3_annotated.mp4\")\n",
    "\n",
    "#sanity check - run the video\n",
    "cap = cv.VideoCapture(path_video2)  \n",
    "current_frame = 0\n",
    "max_number_of_frame_to_run = 750\n",
    "\n",
    "while(cap.isOpened()): \n",
    "    ret, frame = cap.read() # Read the frame\n",
    "    if ret is True: \n",
    "        current_frame = current_frame + 1 \n",
    "        \n",
    "        cv.imshow(\"Frame\",frame)\n",
    "        \n",
    "        if current_frame > max_number_of_frame_to_run:\n",
    "            break\n",
    "            \n",
    "        if cv.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# after playing the video, release the video capture    \n",
    "cap.release()\n",
    "# close all the frames\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the ground-truth file\n",
    "black_ball_gt = np.loadtxt(os.path.join(base_folder, 'video_3_black.txt'))\n",
    "white_ball_gt = np.loadtxt(os.path.join(base_folder, 'video_3_white.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first line contains the lenght (number of frames) of the video (followed by -1 in order to keep the dimension of the array)\n",
    "black_ball_gt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the other lines contains the frame index and the coordinates of the bounding box\n",
    "black_ball_gt[1]\n",
    "# frame_idx, x_min, y_min, x_max, y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"Frame\", first_frame)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_ball_using_hist_of_colors(video_path):\n",
    "    \n",
    "    bboxes = []\n",
    "    \n",
    "    cap = cv.VideoCapture(video_path)\n",
    "    ret, first_frame = cap.read() # Read the first frame \n",
    "    \n",
    "    x, y, w, h = cv.selectROI(first_frame) \n",
    "    track_window = (x, y, w, h)\n",
    "    \n",
    "    roi = first_frame[y: y + h, x: x + w]\n",
    "    annotated_frame = cv.rectangle(first_frame, (x, y), (x+w,y+h), 255, 2)\n",
    " \n",
    "    cv.imshow('First frame initialization', annotated_frame)\n",
    "    cv.waitKey(10000)\n",
    "    \n",
    "    \n",
    "    roi_hist = cv.calcHist([roi], [0 ,1, 2], None, [4, 4, 4], [0, 256, 0, 256, 0, 256]) \n",
    "    roi_hist_norm = roi_hist / roi_hist.sum()\n",
    "\n",
    "    roi_gray = cv.cvtColor(roi, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    frame_idx = 0\n",
    "    while cap.isOpened():\n",
    "        frame_idx += 1\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret is True: \n",
    "            frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "            mask1 = np.int8(np.zeros(frame_gray.shape))\n",
    "            center = (y + h//2, x + h//2)\n",
    "\n",
    "            y_min = np.max((0, center[0] - (2*h)))\n",
    "            y_max = np.min((frame.shape[0], center[0] + (2*h)))\n",
    "            x_min = np.max((0, center[1] - (2*w)))\n",
    "            x_max = np.min((frame.shape[1], center[1] + (2*w)))\n",
    "            \n",
    "            mask1[y_min: y_max, x_min: x_max] = 255\n",
    "\n",
    "            frame_gray_mask = cv.bitwise_and(frame_gray,frame_gray,mask=mask1)\n",
    "            cv.imshow('frame gray mask', frame_gray_mask)\n",
    "            cv.waitKey(500)\n",
    "\n",
    "            res = cv.matchTemplate(frame_gray_mask, roi_gray, cv.TM_CCOEFF_NORMED)        \n",
    "            min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    "\n",
    "            y = max_loc[1]\n",
    "            x = max_loc[0]\n",
    "            bboxes.append([frame_idx, x, y, x + w, y + h])\n",
    "            img2 = cv.rectangle(frame, (x, y), (x + w, y + h), 255, 2)\n",
    "            cv.imshow('img2', img2)\n",
    "\n",
    "            if cv.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "                \n",
    "        else:\n",
    "            break\n",
    "    # after playing the video, release the video capture    \n",
    "    cap.release()\n",
    "    # close all the frames\n",
    "    cv.destroyAllWindows()\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = \"3_table.mp4\"\n",
    "bboxes = track_ball_using_hist_of_colors(os.path.join(\"videos_table\", video_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the intersection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    # return the intersection over union value\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_percentage_tracking(gt_bboxes, predicted_bboxes, num_frames):\n",
    "    num_frames = int(num_frames)\n",
    "    \n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    \n",
    "    gt_dict = {}\n",
    "    for gt_box in gt_bboxes:\n",
    "        gt_dict[gt_box[0]] = gt_box[1:]\n",
    "    \n",
    "    pred_dict = {}\n",
    "    for pred_bbox in predicted_bboxes:\n",
    "        pred_dict[pred_bbox[0]] = pred_bbox[1:]\n",
    "        \n",
    "    for i in range(num_frames):\n",
    "        if gt_dict.get(i, None) is None and pred_dict.get(i, None) is None: # the ball is not on the table\n",
    "            tp += 1 \n",
    "        \n",
    "        elif gt_dict.get(i, None) is not None and pred_dict.get(i, None) is None: # the ball is not detected\n",
    "            fp += 1\n",
    "            \n",
    "        elif gt_dict.get(i, None) is None and pred_dict.get(i, None) is not None: # the ball is not on the table, but it is 'detected'\n",
    "            fp += 1\n",
    "            \n",
    "        elif gt_dict.get(i, None) is not None and pred_dict.get(i, None) is not None: # the ball is on the table and it is detected\n",
    "            \n",
    "            iou = bb_intersection_over_union(gt_dict[i], pred_dict[i])\n",
    "            if iou >= 0.2:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1 \n",
    "             \n",
    "            \n",
    "    print(tp, fp)\n",
    "    assert tp + fp == num_frames\n",
    "    perc = tp / (tp + fp)\n",
    "    \n",
    "    return perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_percentage_tracking(white_ball_gt[1:], bboxes, white_ball_gt[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
