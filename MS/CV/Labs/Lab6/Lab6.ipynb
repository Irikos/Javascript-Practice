{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Vision\n",
    "### Lab 6\n",
    "#### Project 2  - Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template matching for detecting the snooker balls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the templates balls\n",
    "templates = []\n",
    "base_folder_matching = 'template_matching'\n",
    "images_names = glob.glob(os.path.join(base_folder_matching, \"*.jpg\")) \n",
    "for image_name in images_names:      \n",
    "    template = cv.imread(image_name) \n",
    "    templates.append(template) \n",
    "    cv.imshow(\"template\", template)\n",
    "    cv.waitKey(2000)\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "color_dict = {0: \"black\",\n",
    "              1: \"blue\",\n",
    "              2: \"brown\",\n",
    "              3: \"green\",\n",
    "              4: \"pink\",\n",
    "              5: \"red\",\n",
    "              6: \"white\",\n",
    "              7: \"yellow\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the first frame from a video\n",
    "video_path = os.path.join('videos_table', \"4_table.mp4\")\n",
    "\n",
    "cap = cv.VideoCapture(video_path)\n",
    "assert cap.isOpened() is True\n",
    "\n",
    "ret, first_frame = cap.read()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([130, 131, 131, 131, 131, 132, 132, 132, 132, 132, 458, 458, 458,\n",
      "       458, 458, 459, 459, 459, 459, 459, 459, 460, 460, 460]), array([516, 515, 516, 517, 518, 515, 516, 517, 518, 519, 345, 346, 347,\n",
      "       348, 349, 345, 346, 347, 348, 349, 350, 348, 349, 350]))\n",
      "black\n",
      "(array([132, 132, 132, 132, 132, 132, 133, 133, 133, 133, 133, 133, 133,\n",
      "       134, 134, 134, 134, 134, 283, 283, 283, 283, 284, 284, 284, 284,\n",
      "       460, 460, 460, 460, 461, 461, 461]), array([628, 629, 630, 631, 741, 742, 628, 629, 630, 631, 740, 741, 742,\n",
      "       629, 630, 740, 741, 742, 628, 629, 630, 631, 628, 629, 630, 631,\n",
      "       349, 350, 351, 352, 349, 350, 351]))\n",
      "blue\n",
      "(array([133, 133, 133, 134, 134, 134, 134, 134, 135, 284, 284, 284, 285,\n",
      "       285, 536]), array([629, 630, 741, 629, 630, 740, 741, 742, 741, 628, 629, 630, 629,\n",
      "       630, 630]))\n",
      "brown\n",
      "(array([535, 536]), array([627, 627]))\n",
      "green\n",
      "(array([132, 133, 133, 133, 133, 133, 134, 134, 134, 134, 134, 134, 135,\n",
      "       135, 284, 284, 284, 285, 285]), array([630, 629, 630, 631, 741, 742, 629, 630, 631, 741, 742, 743, 741,\n",
      "       742, 629, 630, 631, 630, 631]))\n",
      "pink\n",
      "(array([129, 129, 129, 129, 129, 130, 130, 130, 130, 130, 130, 131, 131,\n",
      "       131, 131, 131, 131, 132, 132, 132, 132, 132, 132, 133, 133, 133,\n",
      "       133, 299, 299, 355, 355, 355, 355, 356, 356, 356, 356, 356, 356,\n",
      "       357, 357, 357, 357, 357, 357, 357, 358, 358, 358, 358, 358, 358,\n",
      "       359, 359, 359, 359, 359, 456, 456, 456, 456, 456, 457, 457, 457,\n",
      "       457, 457, 457, 457, 458, 458, 458, 458, 458, 458, 458, 458, 459,\n",
      "       459, 459, 459, 459, 459, 459, 459, 460, 460, 460, 460, 460]), array([511, 512, 513, 514, 515, 511, 512, 513, 514, 515, 516, 511, 512,\n",
      "       513, 514, 515, 516, 511, 512, 513, 514, 515, 516, 512, 513, 514,\n",
      "       515, 266, 267, 937, 938, 939, 940, 936, 937, 938, 939, 940, 941,\n",
      "       936, 937, 938, 939, 940, 941, 942, 936, 937, 938, 939, 940, 941,\n",
      "       936, 937, 938, 939, 940, 342, 343, 344, 345, 346, 341, 342, 343,\n",
      "       344, 345, 346, 347, 341, 342, 343, 344, 345, 346, 347, 348, 341,\n",
      "       342, 343, 344, 345, 346, 347, 348, 343, 344, 345, 346, 347]))\n",
      "red\n",
      "(array([131, 131, 131, 132, 132, 132, 132, 132, 132, 132, 132, 133, 133,\n",
      "       133, 133, 133, 133, 133, 133, 134, 134, 134, 360, 458, 458, 458,\n",
      "       458, 459, 459, 459, 459, 459, 459, 460, 460, 460, 460, 460, 460,\n",
      "       460, 460, 461, 461, 461, 461, 461, 461, 461, 462, 462, 462]), array([515, 516, 517, 514, 515, 516, 517, 518, 626, 627, 628, 514, 515,\n",
      "       516, 517, 518, 626, 627, 628, 515, 516, 517, 939, 345, 346, 347,\n",
      "       348, 344, 345, 346, 347, 348, 349, 343, 344, 345, 346, 347, 348,\n",
      "       349, 350, 344, 345, 346, 347, 348, 349, 350, 348, 349, 350]))\n",
      "white\n",
      "(array([132, 132, 132, 133, 133, 133, 133, 134, 134, 134, 275, 275, 275,\n",
      "       275, 276, 276, 276, 276, 276, 283, 283, 284, 284, 535]), array([630, 631, 742, 630, 631, 742, 743, 631, 742, 743, 257, 258, 259,\n",
      "       260, 254, 255, 256, 257, 258, 630, 631, 630, 631, 631]))\n",
      "yellow\n"
     ]
    }
   ],
   "source": [
    "# run template matching using a threshold\n",
    "frame = first_frame.copy() \n",
    "idx = -1\n",
    "for template in templates:    \n",
    "    idx = idx + 1\n",
    "    template_gray = cv.cvtColor(template, cv.COLOR_BGR2GRAY)    \n",
    "    w, h = template_gray.shape[::-1]\n",
    "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    res = cv.matchTemplate(frame_gray, template_gray, cv.TM_CCOEFF_NORMED)\n",
    "    cv.imshow(\"Map\", res)\n",
    "    threshold = 0.75\n",
    "    loc = np.where( res >= threshold)\n",
    "    frame_draw = first_frame.copy() \n",
    "    for pt in zip(*loc[::-1]):\n",
    "        cv.rectangle(frame_draw, pt, (pt[0] + w, pt[1] + h), (0,0,255), 1)\n",
    "        \n",
    "    print(color_dict[idx])\n",
    "    cv.imshow(\"Template_matching \" + color_dict[idx], frame_draw)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run template matching using different methods and min/max value\n",
    "frame = first_frame.copy()\n",
    "\n",
    "# All the 6 methods for comparison in a list\n",
    "methods = ['cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED','cv.TM_CCORR',\n",
    "            'cv.TM_CCORR_NORMED', 'cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED' ]\n",
    "\n",
    "# methods = ['cv.TM_CCOEFF_NORMED']\n",
    "\n",
    "idx = -1\n",
    "for template in templates:                \n",
    "    idx = idx + 1\n",
    "    template_gray = cv.cvtColor(template, cv.COLOR_BGR2GRAY)    \n",
    "    w, h = template_gray.shape[::-1]\n",
    "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "       \n",
    "    for meth in methods:        \n",
    "        method = eval(meth)\n",
    "        frame = first_frame.copy()\n",
    "        \n",
    "        # apply template Matching\n",
    "        res = cv.matchTemplate(frame_gray, template_gray,method)\n",
    "         \n",
    "        min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    "\n",
    "        # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "        if method in [cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]:\n",
    "            top_left = min_loc                      \n",
    "        else:\n",
    "            top_left = max_loc\n",
    "            \n",
    "        bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "\n",
    "        cv.rectangle(frame,top_left, bottom_right, 255, 2)\n",
    "        \n",
    "        cv.imshow(\"Template_matching \" + color_dict[idx] +' ' + meth, frame)\n",
    "        cv.waitKey(0)  \n",
    "        cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histrogram of colors for detecting the snooker balls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a method to compute the histogram of a window in the quantized BGR color space\n",
    "def compute_hist(img, bins_0, bins_1, bins_2):\n",
    "    histogram = np.zeros((bins_0, bins_1, bins_2))\n",
    "    length_0 = 256 // bins_0\n",
    "    length_1 = 256 // bins_1\n",
    "    length_2 = 256 // bins_2\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            pixel = img[i][j]\n",
    "            interval_0 = pixel[0] // length_0\n",
    "            interval_1 = pixel[1] // length_1\n",
    "            interval_2 = pixel[2] // length_2\n",
    "            histogram[interval_0, interval_1, interval_2] += 1            \n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select ROI\n",
    "frame = first_frame.copy()\n",
    "x_min, y_min, w, h = cv.selectROI(frame)\n",
    "x_max = x_min + w\n",
    "y_max = y_min + h\n",
    "\n",
    "# Crop image\n",
    "img_crop = frame[y_min:y_max, x_min:x_max]\n",
    "\n",
    "# Display cropped image \n",
    "cv.imshow(\"Image\", img_crop)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[318.   0.   0.   0.]\n",
      "  [127.   1.   0.   0.]\n",
      "  [ 55.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.]]\n",
      "\n",
      " [[  0.   0.   0.   0.]\n",
      "  [  0.   5.   0.   0.]\n",
      "  [  0.   7.   0.   0.]\n",
      "  [  0.   0.   0.   0.]]\n",
      "\n",
      " [[  0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.]\n",
      "  [  0.   0.   2.   0.]\n",
      "  [  0.   0.   5.   5.]]\n",
      "\n",
      " [[  0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   4.]]]\n",
      "529.0\n",
      "529\n"
     ]
    }
   ],
   "source": [
    "# compute the color histogram of the window in the quantized BGR color space\n",
    "# use our function\n",
    "histogram_img = compute_hist(img_crop, 4, 4, 4)\n",
    "print(histogram_img)\n",
    "print(histogram_img.sum())\n",
    "print(img_crop.shape[0] * img_crop.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[318.   0.   0.   0.]\n",
      "  [127.   1.   0.   0.]\n",
      "  [ 55.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.]]\n",
      "\n",
      " [[  0.   0.   0.   0.]\n",
      "  [  0.   5.   0.   0.]\n",
      "  [  0.   7.   0.   0.]\n",
      "  [  0.   0.   0.   0.]]\n",
      "\n",
      " [[  0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.]\n",
      "  [  0.   0.   2.   0.]\n",
      "  [  0.   0.   5.   5.]]\n",
      "\n",
      " [[  0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   4.]]]\n"
     ]
    }
   ],
   "source": [
    "# compute the color histogram of the window in the quantized BGR color space\n",
    "# use the function provided by OpenCV\n",
    "hist_img = cv.calcHist([img_crop], [0, 1, 2], None, [4, 4, 4], [0, 256, 0, 256, 0, 256]) \n",
    "print(hist_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we are going to compute the histograms for our templates\n",
    "hist_templates = []\n",
    "for template in templates:\n",
    "    template_hist = cv.calcHist([template], [0, 1, 2], None, [4, 4, 4], [0, 256, 0, 256, 0, 256])\n",
    "    hist_templates.append(template_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist_templates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-86e5fe0710de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mhist_img_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist_img\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhist_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mhist_template_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist_templates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhist_templates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;31m# use one of the possible distances between histograms - see function cv.compareHist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompareHist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist_img_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist_template_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHISTCMP_CHISQR_ALT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hist_templates' is not defined"
     ]
    }
   ],
   "source": [
    "# Select ROI\n",
    "frame = first_frame.copy()\n",
    "x_min, y_min, w, h = cv.selectROI(frame)\n",
    "x_max = x_min + w\n",
    "y_max = y_min + h\n",
    "\n",
    "# Crop image\n",
    "img_crop = frame[y_min:y_max, x_min:x_max]\n",
    "\n",
    "# Display cropped image \n",
    "cv.imshow(\"Image\", img_crop)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "hist_img = cv.calcHist([img_crop], [0, 1, 2], None, [4, 4, 4], [0, 256, 0, 256, 0, 256]) \n",
    "\n",
    "# do normalization for each histogram\n",
    "distances = []\n",
    "for i in range(len(templates)):\n",
    "    hist_img_norm = hist_img / (hist_img.sum())\n",
    "    hist_template_norm = hist_templates[i] / (hist_templates[i].sum())    \n",
    "    # use one of the possible distances between histograms - see function cv.compareHist\n",
    "    dist = cv.compareHist(hist_img_norm, hist_template_norm, cv.HISTCMP_CHISQR_ALT)\n",
    "    distances.append(dist)\n",
    "print(distances)\n",
    "print(color_dict)\n",
    "print(color_dict[np.argmin(distances)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracking\n",
    "# change the path to match on your machine\n",
    "base_folder = 'videos'\n",
    "path_video1 = os.path.join(base_folder, \"3.mp4\")\n",
    "path_video2 = os.path.join(base_folder, \"3_annotated.mp4\")\n",
    "\n",
    "#sanity check - run the video\n",
    "cap = cv.VideoCapture(path_video2)  \n",
    "current_frame = 0\n",
    "max_number_of_frame_to_run = 750\n",
    "\n",
    "while(cap.isOpened()): \n",
    "    ret, frame = cap.read() # Read the frame\n",
    "    if ret is True: \n",
    "        current_frame = current_frame + 1 \n",
    "        \n",
    "        cv.imshow(\"Frame\",frame)\n",
    "        \n",
    "        if current_frame > max_number_of_frame_to_run:\n",
    "            break\n",
    "            \n",
    "        if cv.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# after playing the video, release the video capture    \n",
    "cap.release()\n",
    "# close all the frames\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the ground-truth file\n",
    "red_ball_gt = np.loadtxt(os.path.join(base_folder, 'video_8_red_1.txt'))\n",
    "white_ball_gt = np.loadtxt(os.path.join(base_folder, 'video_8_white.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([314.,  -1.,  -1.,  -1.,  -1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the first line contains the lenght (number of frames) of the video (followed by -1 in order to keep the dimension of the array)\n",
    "red_ball_gt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"Frame\", first_frame)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'black_ball_gt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-44922f44309f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# the other lines contains the frame index and the coordinates of the bounding box\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mblack_ball_gt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# frame_idx, x_min, y_min, x_max, y_max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'black_ball_gt' is not defined"
     ]
    }
   ],
   "source": [
    "# the other lines contains the frame index and the coordinates of the bounding box\n",
    "black_ball_gt[1]\n",
    "# frame_idx, x_min, y_min, x_max, y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_ball_using_hist_of_colors(video_path):\n",
    "    \n",
    "    bboxes = []\n",
    "    \n",
    "    cap = cv.VideoCapture(video_path)\n",
    "    ret, first_frame = cap.read() # Read the first frame \n",
    "    \n",
    "    x, y, w, h = cv.selectROI(first_frame) \n",
    "    track_window = (x, y, w, h)\n",
    "    \n",
    "    roi = first_frame[y: y + h, x: x + w]\n",
    "    annotated_frame = cv.rectangle(first_frame, (x, y), (x+w,y+h), 255, 2)\n",
    " \n",
    "    cv.imshow('First frame initialization', annotated_frame)\n",
    "    cv.waitKey(10000)\n",
    "    \n",
    "    \n",
    "    roi_hist = cv.calcHist([roi], [0 ,1, 2], None, [4, 4, 4], [0, 256, 0, 256, 0, 256]) \n",
    "    roi_hist_norm = roi_hist / roi_hist.sum()\n",
    "\n",
    "    roi_gray = cv.cvtColor(roi, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    frame_idx = 0\n",
    "    while cap.isOpened():\n",
    "        frame_idx += 1\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret is True: \n",
    "            frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "            mask1 = np.int8(np.zeros(frame_gray.shape))\n",
    "            center = (y + h//2, x + h//2)\n",
    "\n",
    "            y_min = np.max((0, center[0] - (2*h)))\n",
    "            y_max = np.min((frame.shape[0], center[0] + (2*h)))\n",
    "            x_min = np.max((0, center[1] - (2*w)))\n",
    "            x_max = np.min((frame.shape[1], center[1] + (2*w)))\n",
    "            \n",
    "            mask1[y_min: y_max, x_min: x_max] = 255\n",
    "\n",
    "            frame_gray_mask = cv.bitwise_and(frame_gray,frame_gray,mask=mask1)\n",
    "            cv.imshow('frame gray mask', frame_gray_mask)\n",
    "            cv.waitKey(500)\n",
    "\n",
    "            res = cv.matchTemplate(frame_gray_mask, roi_gray, cv.TM_CCOEFF_NORMED)        \n",
    "            min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    "\n",
    "            y = max_loc[1]\n",
    "            x = max_loc[0]\n",
    "            bboxes.append([frame_idx, x, y, x + w, y + h])\n",
    "            img2 = cv.rectangle(frame, (x, y), (x + w, y + h), 255, 2)\n",
    "            cv.imshow('img2', img2)\n",
    "\n",
    "            if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "                \n",
    "        else:\n",
    "            break\n",
    "    # after playing the video, release the video capture    \n",
    "    cap.release()\n",
    "    # close all the frames\n",
    "    cv.destroyAllWindows()\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = \"8_table.mp4\"\n",
    "bboxes = track_ball_using_hist_of_colors(os.path.join(\"videos_table\", video_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the intersection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    # return the intersection over union value\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_percentage_tracking(gt_bboxes, predicted_bboxes, num_frames):\n",
    "    num_frames = int(num_frames)\n",
    "    \n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    \n",
    "    gt_dict = {}\n",
    "    for gt_box in gt_bboxes:\n",
    "        gt_dict[gt_box[0]] = gt_box[1:]\n",
    "    \n",
    "    pred_dict = {}\n",
    "    for pred_bbox in predicted_bboxes:\n",
    "        pred_dict[pred_bbox[0]] = pred_bbox[1:]\n",
    "        \n",
    "    for i in range(num_frames):\n",
    "        if gt_dict.get(i, None) is None and pred_dict.get(i, None) is None: # the ball is not on the table\n",
    "            tp += 1 \n",
    "        \n",
    "        elif gt_dict.get(i, None) is not None and pred_dict.get(i, None) is None: # the ball is not detected\n",
    "            fp += 1\n",
    "            \n",
    "        elif gt_dict.get(i, None) is None and pred_dict.get(i, None) is not None: # the ball is not on the table, but it is 'detected'\n",
    "            fp += 1\n",
    "            \n",
    "        elif gt_dict.get(i, None) is not None and pred_dict.get(i, None) is not None: # the ball is on the table and it is detected\n",
    "            \n",
    "            iou = bb_intersection_over_union(gt_dict[i], pred_dict[i])\n",
    "            if iou >= 0.2:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1 \n",
    "             \n",
    "            \n",
    "    print(tp, fp)\n",
    "    assert tp + fp == num_frames\n",
    "    perc = tp / (tp + fp)\n",
    "    \n",
    "    return perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3877551020408163"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_percentage_tracking(black_ball_gt[1:], bboxes, black_ball_gt[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
