{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Download it through python (inside the code, so you don't have to upload the file too when you send the solution for this exercise) with urlopen() from module urllib and read the entire text in one single string. If the download takes too much time at each running, download the file, but leave the former instructions in a comment (to show that you know how to access an online file) \n",
    "from urllib.request import urlopen\n",
    "proj_g_book = urlopen('https://www.gutenberg.org/files/61587/61587-0.txt')\n",
    "text = proj_g_book.read().decode('utf8')\n",
    "text = str(text)\n",
    "text = text.replace('\\n', ' ')\n",
    "text = text.replace('\\r', ' ')\n",
    "\n",
    "#  Remove the header (keep only the text starting from the title)\n",
    "corpus = text[text.find('The                               Old Church Clock'):]\n",
    "\n",
    "#  Print the number of sentences in the text. Print the average length (number of words) of a sentence.\n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "regex_word_tokenizer = RegexpTokenizer(r'\\w+')\n",
    "sentences = sent_tokenize(corpus)\n",
    "print(f'Number of sentences: {len(sentences)}')\n",
    "\n",
    "#  Create a list of all the words (in lower case) from the text, without the punctuation.\n",
    "word_tokens = regex_word_tokenizer.tokenize(corpus.lower())\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "#  Remove stopwords and assign the result to variable lws\n",
    "lws = [word for word in word_tokens if word not in stopwords]\n",
    "\n",
    "#  Apply stemming (Porter) on the list of words (lws). Print the first 200 words. Do you see any words that don't appear in the dictionary?\n",
    "ps = nltk.PorterStemmer()\n",
    "ls = nltk.LancasterStemmer()\n",
    "snb = nltk.SnowballStemmer(\"english\")\n",
    "lem = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "stems_ps = [ps.stem(word) for word in lws]\n",
    "stems_ps[:200]\n",
    "\n",
    "# Print a table of three columns (of size N, where N is the maximum length for the words in the text). The columns will be separated with the character \"|\". The head of the table will be: \n",
    "table_stem = ['Porter | Lancaster | Snowball']\n",
    "def get_table(table, word_tokens, nw):\n",
    "    for word in word_tokens:\n",
    "        ps_stem = ps.stem(word)\n",
    "        ls_stem = ls.stem(word)\n",
    "        snb_stem = snb.stem(word)\n",
    "        if ps_stem != ls_stem and ps_stem != snb_stem and ls_stem != snb_stem:\n",
    "            bingo = ps_stem + ' | ' + ls_stem + ' | '+ snb_stem\n",
    "            if bingo in table:\n",
    "                continue\n",
    "            table.append(bingo)\n",
    "            if(len(table) == nw):\n",
    "                break\n",
    "    return table\n",
    "\n",
    "table_stem = get_table(table_stem, word_tokens, 500)\n",
    "\n",
    "table_stem\n",
    "\n",
    "# Print a table of two columns, simillar to the one above, that will compare the results of stemming and lemmatization. The head of the table will contain the values: \"Snowball\" and \"WordNetLemmatizer\". The table must contain only words that give different results in the process of stemming and lemmatization (for example, the word \"running\"). The table will contain the results for the first NW words from the text (the number of rows will obviously be less than NW, as not all words match the requirements). For example, NW=500. Try to print only distinct results inside the table (for example, if a word has two occurnces inside the text, and matches the requirments for appearing in the table, it should have only one corresponding row).\n",
    "\n",
    "table_both = ['Snowball | WordNetLemmatizer']\n",
    "def get_table_both(table, word_tokens, nw):\n",
    "    for word in word_tokens:\n",
    "        snb_stem = snb.stem(word)\n",
    "        lem_tok = lem.lemmatize(word)\n",
    "        if snb_stem != lem_tok:\n",
    "            bingo = snb_stem + ' | ' + lem_tok\n",
    "            if bingo in table:\n",
    "                continue\n",
    "            table.append(bingo)\n",
    "            if(len(table) == nw):\n",
    "                break\n",
    "    return table\n",
    "\n",
    "table_both = get_table_both(table_both, word_tokens, 500)\n",
    "table_both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: inflect in /home/mano/anaconda3/lib/python3.7/site-packages (4.1.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/mano/anaconda3/lib/python3.7/site-packages (from inflect) (0.23)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/mano/anaconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->inflect) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /home/mano/anaconda3/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->inflect) (7.2.0)\n"
     ]
    }
   ],
   "source": [
    "# Change all the numbers from lws into words. Print the number of changes, and also the portion of list that contains first N changes (for example N=10).\n",
    "\n",
    "!pip install inflect\n",
    "\n",
    "import inflect\n",
    "p = inflect.engine()\n",
    "\n",
    "new_lws = lws.copy()\n",
    "no_of_changes = 0\n",
    "for idx, tok in enumerate(lws):\n",
    "    try:\n",
    "        number = int(tok)\n",
    "        new_lws[idx] = p.number_to_words(number)\n",
    "        no_of_changes += 1\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "print(f'Number of changes: {no_of_changes}')\n",
    "\n",
    "from nltk.text import Text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_book = Text(word_tokens)\n",
    "\n",
    "nltk_book.concordance('clock', width=59)\n",
    "\n",
    "nltk_book\n",
    "\n",
    "def myfun(N, W, text : nltk.text.Text):\n",
    "    text.concordance_list(W, width=N)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
