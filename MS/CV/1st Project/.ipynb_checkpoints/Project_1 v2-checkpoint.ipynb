{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project 1 v2\n",
    "# Trying a different approach\n",
    "# first read the image, use orb on it no matter what, split the table \n",
    "# then draw the lines or draw the x directly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# Required libraries to be installed: Pillow, OpenCV\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "# from google.colab.patches import cv2_imshow\n",
    "from IPython.display import clear_output, Image, display\n",
    "import PIL.Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = './Simulation/' # change this on your machine\n",
    "# images_n = glob.glob(os.path.join(base_folder, \"image_*.jpg\")) \n",
    "# images_r = glob.glob(os.path.join(base_folder, \"rotation_*.jpg\")) \n",
    "# images_p = glob.glob(os.path.join(base_folder, \"perspective_*.jpg\")) \n",
    "\n",
    "# normal_images = glob.glob(os.path.join(\"./warped/\", \"image_*.jpg\")) \n",
    "# rotated_images = glob.glob(os.path.join(\"./warped_rotated/\", \"rotation_*.jpg\")) \n",
    "# perspective_images = glob.glob(os.path.join(\"./warped_perspective/\", \"perspective_*.jpg\")) \n",
    "template_images = glob.glob(os.path.join('./', \"template_*.jpg\")) \n",
    "char_to_index = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def show_image(a, fmt='jpeg'):\n",
    "    a = np.uint8(np.clip(a, 0, 255))\n",
    "    f = io.BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))\n",
    "    \n",
    "def read_image(index, source, resize):\n",
    "    image = cv.imread(source[index])\n",
    "    return cv.resize(image, (0, 0), fx=resize, fy=resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper variables\n",
    "template_image = read_image(0, template_images, 1)\n",
    "template_image = cv.resize(template_image, (0, 0), fx=0.6, fy=0.6)\n",
    "h, w, _ = template_image.shape\n",
    "template_image = template_image[int(0.36 * h):h, :]\n",
    "# show_image(template_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_options_grid(image):\n",
    "    h, w, _ = image.shape\n",
    "    options_grid = image[int(0.163 * h):int(0.24 * h), int(0.86 * w): int(0.89 * w)]\n",
    "    return options_grid\n",
    "\n",
    "def get_selected_grid(grid):\n",
    "    x_color = (0, 255, 0)  # plot a patch containing an X with green color\n",
    "    blank_color = (0, 0, 255)  # plot a patch containing a blank with red color \n",
    "    colors = [blank_color] * 2\n",
    "    x1_min = 10\n",
    "    x1_max = 60\n",
    "    \n",
    "    x2_min = 10\n",
    "    x2_max = 60\n",
    "    \n",
    "    y1_min = 4\n",
    "    y1_max = 52\n",
    "    \n",
    "    y2_min = 120\n",
    "    y2_max = 170\n",
    "    \n",
    "    \n",
    "    patch1 = image[y1_min:y1_max,x1_min:x1_max].copy().mean()\n",
    "    patch2 = image[y2_min:y2_max,x2_min:x2_max].copy().mean()\n",
    "    patches = [patch1, patch2]\n",
    "    # Get the indices of maximum element in numpy array\n",
    "    min_value = min(patches)\n",
    "    print(min_value)\n",
    "    index = patches.index(min_value)\n",
    "    colors[index] = x_color  \n",
    "    print(index)\n",
    "    \n",
    "    \n",
    "    cv.rectangle(grid, (x1_min, y1_min), (x1_max, y1_max), color=colors[0], thickness=1)\n",
    "    cv.rectangle(grid, (x2_min, y2_min), (x2_max, y2_max), color=colors[1], thickness=1)\n",
    "    show_image(grid)\n",
    "    return index # 0 = I, 1 = F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_grid(image):\n",
    "    image_h, image_w, channels = image.shape\n",
    "    return image[int(0.32 * image_h):int(image_h * 0.78), int(image_w * 0.222): int(image_w * 0.367)]\n",
    "\n",
    "def get_second_grid(image):\n",
    "    image_h, image_w, channels = image.shape\n",
    "    return image[int(0.32 * image_h):int(image_h * 0.79), int(image_w * 0.75): int(image_w * 0.90)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_image(template, query):\n",
    "    img1 = template\n",
    "    img2 = query\n",
    "    # create ORB object\n",
    "    orb = cv.ORB_create(nfeatures=10000)\n",
    "    # get the keypoints and the corresponding descriptors\n",
    "    kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "    kp2, des2 = orb.detectAndCompute(img2, None) \n",
    "    # create BFMatcher object\n",
    "    # matcher takes normType, which is set to cv2.NORM_L2 for SIFT and SURF, cv2.NORM_HAMMING for ORB, FAST and BRIEF\n",
    "    bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    # Match descriptors.\n",
    "    matches = bf.match(des2, des1) # query_image, train_image\n",
    "    # Sort them in the order of their distance.\n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "    # points template from img1, the template image\n",
    "    points_template = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "    # points_query from img2, the query image\n",
    "    points_query = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "    for i,m in enumerate(matches):\n",
    "        points_template[i,:] = kp1[m.trainIdx].pt\n",
    "        points_query[i,:] = kp2[m.queryIdx].pt\n",
    "\n",
    "    H,mask = cv.findHomography(points_query, points_template, cv.RANSAC)\n",
    "\n",
    "    # use homography to get the aligned image \n",
    "    height, width, _ = template.shape # the shape with respect to the template image\n",
    "    aligned_image2 = cv.warpPerspective(query, H, (width, height), flags=cv.INTER_NEAREST)\n",
    "\n",
    "    return aligned_image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_x_from_table(table):\n",
    "    table_gray = cv.cvtColor(table, cv.COLOR_BGR2GRAY)\n",
    "    image = np.dstack((table_gray, table_gray, table_gray))\n",
    "    x_color = (0, 255, 0)  # plot a patch containing an X with green color\n",
    "    blank_color = (0, 0, 255)  # plot a patch containing a blank with red color \n",
    "    x_positions = [0] * 15\n",
    "    w, h, _ = image.shape\n",
    "    cell_height = int(h / 5)\n",
    "    cell_width = int(w / 4)\n",
    "    # y6_min putin mai jos (aka mai mare)\n",
    "    # 11 mai sus (mai mic), 9 mai jos (mai mare)\n",
    "#     y_mins = [3, 22, 38, 55, 72, 88, 106, 123, 138, 156, 176, 190, 207, 224, 243]\n",
    "#     y_mins = [5, 24, 40, 57, 74, 90, 108, 125, 140, 158, 178, 192, 209, 226, 245]\n",
    "    y_mins = [5, 24, 40, 57, 75, 90, 108, 125, 142, 159, 176, 192, 210, 227, 245]\n",
    "    for i in range(0, 15):\n",
    "        colors = [blank_color] * 4\n",
    "            \n",
    "        y_min = y_mins[i]\n",
    "        y_max = y_min + 10\n",
    "            \n",
    "        x1_min = 4\n",
    "        x1_max = 20\n",
    "        \n",
    "        x2_min = 27\n",
    "        x2_max = 42\n",
    "        \n",
    "        x3_min = 48\n",
    "        x3_max = 64\n",
    "        \n",
    "        x4_min = 71\n",
    "        x4_max = 84\n",
    "        \n",
    "#         x1_min = 4\n",
    "#         x1_max = 22\n",
    "        \n",
    "#         x2_min = 26\n",
    "#         x2_max = 44\n",
    "        \n",
    "#         x3_min = 46\n",
    "#         x3_max = 66\n",
    "        \n",
    "#         x4_min = 68\n",
    "#         x4_max = 87\n",
    "        \n",
    "        patch1 = image[y_min:y_max,x1_min:x1_max].copy().mean()\n",
    "        patch2 = image[y_min:y_max,x2_min:x2_max].copy().mean()\n",
    "        patch3 = image[y_min:y_max,x3_min:x3_max].copy().mean()\n",
    "        patch4 = image[y_min:y_max,x4_min:x4_max].copy().mean()\n",
    "        patches = [patch1, patch2, patch3, patch4]\n",
    "        \n",
    "        # Get the indices of maximum element in numpy array\n",
    "        min_value = min(patches)\n",
    "        index = patches.index(min_value)\n",
    "        colors[index] = x_color\n",
    "        x_positions[i] = index\n",
    "        cv.rectangle(image, (x1_min, y_min), (x1_max, y_max), color=colors[0], thickness=1)\n",
    "        cv.rectangle(image, (x2_min, y_min), (x2_max, y_max), color=colors[1], thickness=1)\n",
    "        cv.rectangle(image, (x3_min, y_min), (x3_max, y_max), color=colors[2], thickness=1)\n",
    "        cv.rectangle(image, (x4_min, y_min), (x4_max, y_max), color=colors[3], thickness=1)\n",
    "# I return both the image and the position so that I can show the image if the positions do not match\n",
    "    return (x_positions, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_result(ground_truth, detected_values):\n",
    "    for i in range(0, 15):\n",
    "        if (int(char_to_index[ground_truth[i][1]]) != detected_values[i]):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth_answers(path):\n",
    "    file_names = glob.glob(os.path.join(path, '*.txt')) \n",
    "    phisycs = []\n",
    "    informatics = np.empty((4,), dtype=object)\n",
    "    physics = np.empty((4,), dtype=object)\n",
    "    ground_truth = {}\n",
    "    for file in file_names:\n",
    "        data = np.loadtxt(file, dtype=str)\n",
    "        option = data[0][0]\n",
    "        variant = int(data[0][1])\n",
    "        if (option == 'I'):\n",
    "            informatics[variant - 1] = data[1:-1]\n",
    "        if (option == 'F'):\n",
    "            physics[variant - 1] = data[1:-1]\n",
    "    ground_truth['F'] = physics\n",
    "    ground_truth['I'] = informatics\n",
    "    return ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers_from_image(image):\n",
    "    # it gives different results if I apply 0.25 resize directly. The code initially had a different\n",
    "    # structure where it made sense and I don't have time to change now it since it works\n",
    "#     show_image(image)\n",
    "#     warped = warp_image(template_image, image)\n",
    "#     resized = cv.resize(warped, (0,0), fx=0.5, fy=0.5)\n",
    "#     resized = cv.resize(image, (0,0), fx=0.5, fy=0.5)\n",
    "    table1 = get_first_grid(image)\n",
    "    table2 = get_second_grid(image)\n",
    "    \n",
    "    table_x1 = find_x_from_table(table1)\n",
    "    table_x2 = find_x_from_table(table2)\n",
    "#     show_image(table_x1[1])\n",
    "#     show_image(table_x2[1])\n",
    "    results = table_x1[0] + table_x2[0]   \n",
    "    return (results, table_x1[1], table_x2[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answers = computed answers from the image\n",
    "# options = I / F\n",
    "# variant = 1, 2, 3 or 4\n",
    "\n",
    "def calculate_grade(answers, ground_truth, option, variant):\n",
    "    grade = 0\n",
    "    for i in range (0, 30):\n",
    "        # variant - 1 so that we map 1..4 to 0..3\n",
    "        ground_truth_answer = ground_truth[option][variant - 1][i][1] \n",
    "        if (answers[i] == char_to_index[ground_truth_answer]):\n",
    "            grade += 0.3\n",
    "    return round(grade + 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_read_answers(image_number, answers):\n",
    "    file = os.path.join(base_folder, 'image_%s.txt' % image_number)\n",
    "    data = np.loadtxt(file, dtype=str)[1:-1]  \n",
    "    for i in range(0, 30):\n",
    "        if (char_to_index[data[i][1]] != answers[i]):\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def verify_grade(image_number, grade):\n",
    "    file = os.path.join(base_folder, 'image_%s.txt' % image_number)\n",
    "    data = np.loadtxt(file, dtype=str)[-1]  \n",
    "    if (round(float(data[1]) * 0.3 + 1, 2) != grade):\n",
    "        return False    \n",
    "    return True\n",
    "\n",
    "def verify_grade_file(image_number, grade):\n",
    "    file = os.path.join(base_folder, 'images_grades_from_text.txt')\n",
    "    data = np.loadtxt(file, dtype=str)\n",
    "    read_image_no = int(data[image_number - 1][0])\n",
    "    read_image_grade = float(data[image_number - 1][1])\n",
    "    if (image_number != read_image_no):\n",
    "        print (\"SOMETHING IS WRONG\")\n",
    "        return False\n",
    "    else:\n",
    "        if (grade != read_image_grade):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_scanned_F1   4.9   True\n",
      "02_scanned_I3   6.7   True\n",
      "03_scanned_I1   5.8   True\n",
      "04_scanned_F3   8.5   True\n",
      "05_scanned_I2   4.9   True\n",
      "06_scanned_I4   6.7   True\n",
      "07_scanned_I2   9.1   True\n",
      "08_scanned_I1   3.7   True\n",
      "09_scanned_F4   5.5   True\n",
      "10_scanned_I1   5.5   True\n",
      "11_scanned_F1   4.6   True\n",
      "12_scanned_F3   6.7   True\n",
      "13_scanned_I4   7.3   True\n",
      "14_scanned_F1   6.4   True\n",
      "15_scanned_F1   7.0   True\n",
      "16_scanned_F4   4.6   True\n",
      "17_scanned_I1   7.6   True\n",
      "18_scanned_I2   6.1   True\n",
      "19_scanned_I1   4.9   True\n",
      "20_scanned_F1   7.6   True\n",
      "21_scanned_F3   6.4   True\n",
      "22_scanned_F4   5.5   True\n",
      "23_scanned_F4   6.4   True\n",
      "24_scanned_F2   7.3   True\n",
      "25_scanned_I4   7.9   True\n",
      "26_scanned_F2   8.5   True\n",
      "27_scanned_I3   5.5   True\n",
      "28_scanned_F3   8.8   True\n",
      "29_scanned_I2   6.1   True\n",
      "30_scanned_F1   7.9   True\n",
      "31_scanned_F2   4.9   True\n",
      "32_scanned_F1   5.2   True\n",
      "33_scanned_F1   7.6   True\n",
      "34_scanned_I3   7.0   True\n",
      "35_scanned_F1   7.0   True\n",
      "36_scanned_F2   6.4   True\n",
      "37_scanned_F3   8.8   True\n",
      "38_scanned_I1   6.7   True\n",
      "39_scanned_F4   7.0   True\n",
      "40_scanned_I3   5.8   True\n",
      "41_scanned_F2   7.6   True\n",
      "42_scanned_I3   9.7   True\n",
      "43_scanned_F4   6.7   True\n",
      "44_scanned_F3   6.4   True\n",
      "45_scanned_I3   5.5   True\n",
      "46_scanned_F1   7.3   True\n",
      "47_scanned_F4   8.8   True\n",
      "48_scanned_F2   6.4   True\n",
      "49_scanned_I3   5.8   True\n",
      "50_scanned_F1   7.0   True\n",
      "51_scanned_F3   8.2   True\n",
      "52_scanned_I4   4.9   True\n",
      "53_scanned_I4   4.3   True\n",
      "54_scanned_I2   8.8   True\n",
      "55_scanned_F1   8.2   True\n",
      "56_scanned_F2   5.2   True\n",
      "57_scanned_I2   5.2   True\n",
      "58_scanned_F4   5.5   True\n",
      "59_scanned_F3   7.0   True\n",
      "60_scanned_F2   7.9   True\n",
      "61_scanned_F3   4.9   True\n",
      "62_scanned_F1   4.6   True\n",
      "63_scanned_I2   5.2   True\n",
      "64_scanned_I4   7.6   True\n",
      "65_scanned_F1   7.0   True\n",
      "66_scanned_I3   9.4   True\n",
      "67_scanned_F2   7.3   True\n",
      "68_scanned_I3   4.6   True\n",
      "69_scanned_F2   4.3   True\n",
      "70_scanned_I2   4.0   True\n",
      "71_scanned_F3   6.4   True\n",
      "72_scanned_F1   4.9   True\n",
      "73_scanned_I2   5.5   True\n",
      "74_scanned_F4   9.4   True\n",
      "75_scanned_F1   4.0   True\n",
      "76_scanned_I3   6.1   True\n",
      "77_scanned_F3   7.3   True\n",
      "78_scanned_I1   4.0   True\n",
      "79_scanned_F2   5.5   True\n",
      "80_scanned_F3   5.5   True\n",
      "81_scanned_F2   8.5   True\n",
      "82_scanned_I1   4.9   True\n",
      "83_scanned_F1   6.7   True\n",
      "84_scanned_F2   5.2   True\n",
      "85_scanned_I3   7.6   True\n",
      "86_scanned_I3   4.9   True\n",
      "87_scanned_I1   5.5   True\n",
      "88_scanned_F1   9.1   True\n",
      "89_scanned_I4   6.4   True\n",
      "90_scanned_I1   6.1   True\n",
      "91_scanned_I2   6.1   True\n",
      "92_scanned_I2   5.5   True\n",
      "93_scanned_I4   4.6   True\n",
      "94_scanned_F2   7.9   True\n",
      "95_scanned_I4   4.6   True\n",
      "96_scanned_I1   6.7   True\n",
      "97_scanned_F2   5.5   True\n",
      "98_scanned_F3   5.5   True\n",
      "99_scanned_F4   7.3   True\n",
      "100_scanned_I3   4.9   True\n",
      "101_scanned_I2   4.9   True\n",
      "102_scanned_F2   5.2   True\n",
      "103_scanned_F2   5.5   True\n",
      "104_scanned_I3   5.2   True\n",
      "105_scanned_F1   4.0   True\n",
      "106_scanned_I3   6.4   True\n",
      "107_scanned_F2   9.7   True\n",
      "108_scanned_F3   8.8   True\n",
      "109_scanned_I4   5.8   True\n",
      "110_scanned_F2   7.3   True\n",
      "111_scanned_F4   6.1   True\n",
      "112_scanned_I3   4.3   True\n",
      "113_scanned_F4   6.1   True\n",
      "114_scanned_I4   6.4   True\n",
      "115_scanned_F4   5.2   True\n",
      "116_scanned_F2   6.4   True\n",
      "117_scanned_I1   4.9   True\n",
      "118_scanned_I1   3.7   True\n",
      "119_scanned_F4   5.8   True\n",
      "120_scanned_F2   4.6   True\n",
      "121_scanned_F1   6.7   True\n",
      "122_scanned_F2   5.5   True\n",
      "123_scanned_I4   4.0   True\n",
      "124_scanned_F1   8.8   True\n",
      "125_scanned_I2   6.4   True\n",
      "126_scanned_I2   4.3   True\n",
      "127_scanned_F3   7.3   True\n",
      "128_scanned_F3   8.8   True\n",
      "129_scanned_F2   6.4   True\n",
      "130_scanned_I1   4.3   True\n",
      "131_scanned_I1   6.4   True\n",
      "132_scanned_I1   4.3   True\n",
      "133_scanned_F1   3.7   True\n",
      "134_scanned_F1   6.4   True\n",
      "135_scanned_F4   7.6   True\n",
      "136_scanned_F4   5.8   True\n",
      "137_scanned_F4   5.8   True\n",
      "138_scanned_F2   6.7   True\n",
      "139_scanned_I3   4.6   True\n",
      "140_scanned_F3   7.3   True\n",
      "141_scanned_F1   5.5   True\n",
      "142_scanned_I4   4.3   True\n",
      "143_scanned_I4   6.4   True\n",
      "144_scanned_F3   8.8   True\n",
      "145_scanned_F1   6.7   True\n",
      "146_scanned_I2   4.3   True\n",
      "147_scanned_F3   5.8   True\n",
      "148_scanned_F3   7.3   True\n",
      "149_scanned_I4   7.6   True\n",
      "150_scanned_I3   6.4   True\n"
     ]
    }
   ],
   "source": [
    "# Scenario 1\n",
    "# ground truth, the 8 possible grading scenarios\n",
    "ground_truth_answers_path = './Files/ground-truth-correct-answers'\n",
    "ground_truth = get_ground_truth_answers(ground_truth_answers_path)\n",
    "# images folder\n",
    "images = glob.glob(\"./Simulation/scenario_1/*.jpg\") \n",
    "images.sort(key = lambda x: int(x.split('/')[-1].split('_')[0]))\n",
    "total = len(images)\n",
    "\n",
    "# answers file\n",
    "answers_file = open('dumitriu_andrei_task1.txt', 'w+')\n",
    "count = 0 # the number of correctly read answers\n",
    "for i in range(0, total):\n",
    "    image_name = images[i].split('/')[-1].split('.')[0]\n",
    "    option = image_name[-2]\n",
    "    variant = int(image_name[-1])\n",
    "    image_number = int(images[i].split('/')[-1].split('.')[0].split('_')[0])\n",
    "#     print(image_name)\n",
    "#     print(option)\n",
    "#     print(variant)\n",
    "#     print(image_number)\n",
    "    \n",
    "    image = read_image(i, images, 1)\n",
    "    warped1 = warp_image(template_image, image)\n",
    "    warped = warp_image(template_image, warped1)\n",
    "    resized = cv.resize(warped, (0,0), fx=0.5, fy=0.5)\n",
    "    image = cv.resize(resized, (0,0), fx=0.5, fy=0.5)\n",
    "    \n",
    "    answers = get_answers_from_image(image)[0]\n",
    "    grade = calculate_grade(answers, ground_truth, option, variant)\n",
    "    \n",
    "    written_string = str(image_name + \"    \" + str(grade))\n",
    "    answers_file.write(written_string)\n",
    "    answers_file.write('\\n')\n",
    "    \n",
    "    # verify, can de deleted afterwards\n",
    "    verified = verify_grade_file(image_number, grade)\n",
    "    if (verified == True):\n",
    "        count += 1\n",
    "    else:\n",
    "        print('\\n')\n",
    "        print(image_name, ' ', answers)\n",
    "        show_image(table1)\n",
    "        show_image(table2)\n",
    "        print('\\n')\n",
    "    print(image_name, ' ', grade, ' ', verified)\n",
    "    # end of deletion\n",
    "    \n",
    "\n",
    "answers_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (count * 100 / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) ../modules/imgproc/src/thresh.cpp:1529: error: (-215:Assertion failed) src.type() == CV_8UC1 in function 'threshold'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-539-e6c5243f13ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mblur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mret3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mth3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblur\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_OTSU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mshow_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.2.0) ../modules/imgproc/src/thresh.cpp:1529: error: (-215:Assertion failed) src.type() == CV_8UC1 in function 'threshold'\n"
     ]
    }
   ],
   "source": [
    "# Scenario 2\n",
    "# ground truth, the 8 possible grading scenarios\n",
    "ground_truth_answers_path = './Files/ground-truth-correct-answers'\n",
    "ground_truth = get_ground_truth_answers(ground_truth_answers_path)\n",
    "# images folder\n",
    "images = glob.glob(\"./Simulation/scenario_2/*.jpg\")\n",
    "images.sort()\n",
    "total = len(images)\n",
    "# total = 1\n",
    "\n",
    "# answers file\n",
    "answers_file = open('dumitriu_andrei_task2.txt', 'w+')\n",
    "count = 0 # the number of correctly read answers\n",
    "for i in range(0, total):\n",
    "    image_name = images[i].split('/')[-1].split('.')[0]\n",
    "    option = image_name[-2]\n",
    "    variant = int(image_name[-1])\n",
    "    image_number = int(images[i].split('/')[-1].split('.')[0].split('_')[0])\n",
    "#     print(image_name)\n",
    "#     print(option)\n",
    "#     print(variant)\n",
    "#     print(image_number)\n",
    "    \n",
    "    image = read_image(i, images, 1)\n",
    "    warped1 = warp_image(template_image, image)\n",
    "    warped = warp_image(template_image, warped1)\n",
    "    resized = cv.resize(warped, (0,0), fx=0.5, fy=0.5)\n",
    "    image = cv.resize(resized, (0,0), fx=0.5, fy=0.5)\n",
    "    \n",
    "    answers = get_answers_from_image(image)[0]\n",
    "    \n",
    "    table1 = get_answers_from_image(image)[1]\n",
    "    table2 = get_answers_from_image(image)[2]\n",
    "    \n",
    "    grade = calculate_grade(answers, ground_truth, option, variant)\n",
    "    \n",
    "    written_string = str(image_name + \"    \" + str(grade))\n",
    "    answers_file.write(written_string)\n",
    "    answers_file.write('\\n')\n",
    "    \n",
    "    # verify, can de deleted afterwards\n",
    "    verified = verify_grade_file(image_number, grade)\n",
    "    if (verified == True):\n",
    "        count += 1\n",
    "    else:\n",
    "        print('\\n')\n",
    "        print(image_name, ' ', answers)\n",
    "        show_image(table1)\n",
    "        show_image(table2)\n",
    "        print('\\n')\n",
    "    print(image_name, ' ', grade, ' ', verified)\n",
    "    # end of deletion\n",
    "\n",
    "answers_file.close()\n",
    "print (count * 100 / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_options_grid(image):\n",
    "    h, w, _ = image.shape\n",
    "    options_grid = image[int(0.163 * h):int(0.245 * h), int(0.862 * w): int(0.89 * w)]\n",
    "#     options_grid = image[int(0.163 * h):int(0.245 * h), int(0.56 * w): int(0.89 * w)]\n",
    "    \n",
    "#     options_grid = cv.medianBlur(options_grid, 5)\n",
    "    options_grid = cv.cvtColor(options_grid, cv.COLOR_BGR2GRAY)\n",
    "    (thresh, options_black_and_white) = cv.threshold(options_grid, 127, 255, cv.THRESH_BINARY)\n",
    "    return options_black_and_white\n",
    "\n",
    "def get_selected_grid(grid1):\n",
    "    x_color = (0, 255, 0)  # plot a patch containing an X with green color\n",
    "    blank_color = (0, 0, 255)  # plot a patch containing a blank with red color\n",
    "    \n",
    "    grid = np.dstack((grid1, grid1, grid1))\n",
    "    colors = [blank_color] * 2\n",
    "    x1_min = 10\n",
    "    x1_max = 50\n",
    "    \n",
    "    x2_min = 10\n",
    "    x2_max = 50\n",
    "    \n",
    "    y1_min = 10\n",
    "    y1_max = 50\n",
    "    \n",
    "    y2_min = 125\n",
    "    y2_max = 165\n",
    "    \n",
    "    \n",
    "    patch1 = image[y1_min:y1_max,x1_min:x1_max].copy().mean()\n",
    "    patch2 = image[y2_min:y2_max,x2_min:x2_max].copy().mean()\n",
    "    patches = [patch1, patch2]\n",
    "    # Get the indices of maximum element in numpy array\n",
    "    min_value = min(patches)\n",
    "    index = patches.index(min_value)\n",
    "    colors[index] = x_color      \n",
    "    \n",
    "    cv.rectangle(grid, (x1_min, y1_min), (x1_max, y1_max), color=colors[0], thickness=1)\n",
    "    cv.rectangle(grid, (x2_min, y2_min), (x2_max, y2_max), color=colors[1], thickness=1)\n",
    "#     show_image(grid)\n",
    "    return index # 0 = I, 1 = F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) ../modules/imgproc/src/thresh.cpp:1529: error: (-215:Assertion failed) src.type() == CV_8UC1 in function 'threshold'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-540-02beac856d87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mblur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mret3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mth3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblur\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_OTSU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0moptions_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_options_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.2.0) ../modules/imgproc/src/thresh.cpp:1529: error: (-215:Assertion failed) src.type() == CV_8UC1 in function 'threshold'\n"
     ]
    }
   ],
   "source": [
    "# Scenario 3\n",
    "# ground truth, the 8 possible grading scenarios\n",
    "ground_truth_answers_path = './Files/ground-truth-correct-answers'\n",
    "ground_truth = get_ground_truth_answers(ground_truth_answers_path)\n",
    "# \"real\" images folder\n",
    "# images = glob.glob(\"./Simulation/scenario_3/*.jpg\")\n",
    "\n",
    "# \"test\" images folder\n",
    "images = glob.glob(\"./Files/images/*.jpg\")\n",
    "\n",
    "total = len(images)\n",
    "# total = 1\n",
    "\n",
    "# answers file\n",
    "answers_file = open('dumitriu_andrei_task3.txt', 'w+')\n",
    "count = 0 # the number of correctly read answers\n",
    "for i in range(0, total):\n",
    "    # for real images\n",
    "#     image_name = images[i].split('/')[-1].split('.')[0]\n",
    "#     option = image_name[-2]\n",
    "#     variant = int(image_name[-1])  \n",
    "#     image_number = int(images[i].split('/')[-1].split('.')[0].split('_')[0])\n",
    "\n",
    "\n",
    "    # for test images\n",
    "    image_name = \"image_\" + images[i].split('/')[-1].split('.')[-2].split('_')[-1]\n",
    "    image_number = int(image_name.split('_')[-1])\n",
    "    file = os.path.join('./Files/images', 'image_%s.txt' % image_number)\n",
    "    data = np.loadtxt(file, dtype=str)\n",
    "    option = data[0][0]\n",
    "    variant = int(data[0][1])\n",
    "    real_grade = int(data[-1][1]) * 0.3 + 1\n",
    "    # end of test\n",
    "    \n",
    "    \n",
    "\n",
    "#     print(image_name)\n",
    "#     print(option)\n",
    "#     print(variant)\n",
    "#     print(image_number)\n",
    "    \n",
    "    \n",
    "    image = read_image(i, images, 1)\n",
    "    warped = warp_image(template_image, image)\n",
    "    resized = cv.resize(warped, (0,0), fx=0.5, fy=0.5)\n",
    "    image = cv.resize(resized, (0,0), fx=0.5, fy=0.5)\n",
    "    \n",
    "    options_grid = get_options_grid(warped)\n",
    "#     show_image(options_grid)\n",
    "    get_selected_grid(options_grid)\n",
    "    \n",
    "    \n",
    "    answers = get_answers_from_image(image)[0]    \n",
    "\n",
    "    \n",
    "    table1 = get_answers_from_image(image)[1]\n",
    "    table2 = get_answers_from_image(image)[2]\n",
    "    \n",
    "    max_grade = 0\n",
    "    guessed_option = 'F'\n",
    "    guessed_variant = 1\n",
    "    for i in range (1, 5):\n",
    "        f_grade = calculate_grade(answers, ground_truth, 'F', i)\n",
    "        i_grade = calculate_grade(answers, ground_truth, 'I', i)\n",
    "        if (max_grade < f_grade):\n",
    "            guessed_option = 'F'\n",
    "            guessed_variant = i\n",
    "            max_grade = f_grade\n",
    "            \n",
    "        if (max_grade < i_grade):\n",
    "            guessed_option = 'I'\n",
    "            guessed_variant = i\n",
    "            max_grade = i_grade\n",
    "            \n",
    "    grade = calculate_grade(answers, ground_truth, guessed_option, guessed_variant)\n",
    "    \n",
    "    written_string = str(image_name + \"    \" + str(grade))\n",
    "    answers_file.write(written_string)\n",
    "    answers_file.write('\\n')\n",
    "    \n",
    "    # verify, can de deleted afterwards\n",
    "    verified = verify_grade_file(image_number, grade)\n",
    "    if (verified == True):\n",
    "        count += 1\n",
    "        print(image_name)\n",
    "    else:\n",
    "        print('\\n')\n",
    "        print(\"real option:\", option)\n",
    "        print(\"real variant:\", variant)\n",
    "        print(\"real grade:\", real_grade)\n",
    "        print(\"guessed option:\", guessed_option)\n",
    "        print(\"guessed variant:\", guessed_variant)\n",
    "        print(\"guessed grade:\", grade)\n",
    "        print('\\n')\n",
    "    # end of deletion\n",
    "\n",
    "answers_file.close()\n",
    "print (count * 100 / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK, Jupyter, you can do this.\n",
      "Testing on normal images....\n",
      "100%, Normal Jupyter ftw!\n"
     ]
    }
   ],
   "source": [
    "total = 150\n",
    "count = 0\n",
    "# NORMAL\n",
    "# # print(warped_images[1])\n",
    "print (\"OK, Jupyter, you can do this.\")\n",
    "print (\"Testing on normal images....\")\n",
    "for i in range(0, total):\n",
    "    ## CAREFUL. READING IT AT 0.5 AND THEN RESIZING AGAIN TO 0.5\n",
    "    \n",
    "    image_n = read_image(i, normal_images, 0.5)\n",
    "#     image_r = read_image(i, rotated_images, 0.5)\n",
    "#     image_p = read_image(0, perspective_images, 0.5)\n",
    "    resized = cv.resize(image_n, (0,0), fx=0.5, fy=0.5)\n",
    "    image_name = \"image_\" + normal_images[i].split('/')[-1].split('.')[-2].split('_')[-1]\n",
    "#     print(image_name)\n",
    "    table1 = get_first_grid(resized)\n",
    "    table2 = get_second_grid(resized)\n",
    "    \n",
    "    table_x1 = find_x_from_table(table1)\n",
    "    table_x2 = find_x_from_table(table2)\n",
    "    \n",
    "    \n",
    "    results = table_x1[0] + table_x2[0]    \n",
    "    ground_truth_content = np.loadtxt(os.path.join(base_folder, '%s.txt' % image_name), dtype=str)[1:-1]\n",
    "#     print(results)\n",
    "#     print(ground_truth_content)\n",
    "    correct = verify_result(ground_truth_content, results)\n",
    "    if (correct == True):\n",
    "        count += 1\n",
    "    else:\n",
    "        show_image(table_x1[1])\n",
    "        show_image(table_x2[1])\n",
    "    \n",
    "\n",
    "percentage = count * 100 / total\n",
    "if (percentage == 100):\n",
    "        print ('100%, Normal Jupyter ftw!')\n",
    "else:\n",
    "    print(percentage)\n",
    "    print('not quite there yet, keep trying!')\n",
    "\n",
    "\n",
    "# # ROTATED\n",
    "# total = 150\n",
    "# count = 0\n",
    "# print (\"Testing on rotated images....\")\n",
    "# for i in range(0, total):\n",
    "#     ## CAREFUL. READING IT AT 0.5 AND THEN RESIZING AGAIN TO 0.5\n",
    "    \n",
    "# #     image_n = read_image(i, images_n, 0.5)\n",
    "#     image_r = read_image(i, rotated_images, 0.5)\n",
    "# #     image_p = read_image(0, perspective_images, 0.5)\n",
    "#     resized = cv.resize(image_r, (0,0), fx=0.5, fy=0.5)\n",
    "#     image_name = \"image_\" + rotated_images[i].split('/')[-1].split('.')[-2].split('_')[-1]\n",
    "# #     print(image_name)\n",
    "#     table1 = get_first_grid(resized)\n",
    "#     table2 = get_second_grid(resized)\n",
    "    \n",
    "#     table_x1 = find_x_from_table(table1)\n",
    "#     table_x2 = find_x_from_table(table2)\n",
    "    \n",
    "    \n",
    "#     results = table_x1[0] + table_x2[0]    \n",
    "#     ground_truth_content = np.loadtxt(os.path.join(base_folder, '%s.txt' % image_name), dtype=str)[1:-1]\n",
    "# #     print(results)\n",
    "# #     print(ground_truth_content)\n",
    "#     correct = verify_result(ground_truth_content, results)\n",
    "#     if (correct == True):\n",
    "#         count += 1\n",
    "#     else:\n",
    "#         show_image(table_x1[1])\n",
    "#         show_image(table_x2[1])\n",
    "# percentage = count * 100 / total\n",
    "# if (percentage == 100):\n",
    "#         print ('100%, Rotated Jupyter ftw!')\n",
    "# else:\n",
    "#     print(percentage)\n",
    "#     print('Not quite there yet, keep trying!')\n",
    "    \n",
    "# # PERSPECTIVE\n",
    "# total = 150\n",
    "# count = 0\n",
    "# print (\"Testing on perspective images....\")\n",
    "# for i in range(0, total):\n",
    "#     ## CAREFUL. READING IT AT 0.5 AND THEN RESIZING AGAIN TO 0.5\n",
    "    \n",
    "# #     image_n = read_image(i, images_n, 0.5)\n",
    "# #     image_r = read_image(i, rotated_images, 0.5)\n",
    "#     image_p = read_image(i, perspective_images, 0.5)\n",
    "#     resized = cv.resize(image_p, (0,0), fx=0.5, fy=0.5)\n",
    "#     image_name = \"image_\" + perspective_images[i].split('/')[-1].split('.')[-2].split('_')[-1]\n",
    "# #     print(image_name)\n",
    "#     table1 = get_first_grid(resized)\n",
    "#     table2 = get_second_grid(resized)\n",
    "    \n",
    "#     table_x1 = find_x_from_table(table1)\n",
    "#     table_x2 = find_x_from_table(table2)\n",
    "    \n",
    "    \n",
    "#     results = table_x1[0] + table_x2[0]    \n",
    "#     ground_truth_content = np.loadtxt(os.path.join(base_folder, '%s.txt' % image_name), dtype=str)[1:-1]\n",
    "# #     print(results)\n",
    "# #     print(ground_truth_content)\n",
    "#     correct = verify_result(ground_truth_content, results)\n",
    "#     if (correct == True):\n",
    "#         count += 1\n",
    "#     else:\n",
    "#         print(image_name)\n",
    "#         show_image(table_x1[1])\n",
    "#         show_image(table_x2[1])\n",
    "# percentage = count * 100 / total\n",
    "    \n",
    "\n",
    "# if (percentage == 100):\n",
    "#         print ('100%, Perspective Jupyter ftw!')\n",
    "# else:\n",
    "#     print(percentage)\n",
    "#     print('Not quite there yet, keep trying!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perspective_36\n",
      "perspective_21\n",
      "perspective_96\n",
      "perspective_15\n",
      "perspective_8\n",
      "perspective_89\n",
      "perspective_39\n",
      "perspective_9\n",
      "perspective_135\n",
      "perspective_46\n",
      "perspective_55\n",
      "perspective_53\n",
      "perspective_28\n",
      "perspective_37\n",
      "perspective_57\n",
      "perspective_63\n",
      "perspective_109\n",
      "perspective_17\n",
      "perspective_105\n",
      "perspective_124\n",
      "perspective_24\n",
      "perspective_19\n",
      "perspective_138\n",
      "perspective_5\n",
      "perspective_128\n",
      "perspective_52\n",
      "perspective_139\n",
      "perspective_100\n",
      "perspective_83\n",
      "perspective_56\n",
      "perspective_85\n",
      "perspective_20\n",
      "perspective_40\n",
      "perspective_76\n",
      "perspective_10\n",
      "perspective_23\n",
      "perspective_65\n",
      "perspective_45\n",
      "perspective_130\n",
      "perspective_82\n",
      "perspective_88\n",
      "perspective_25\n",
      "perspective_117\n",
      "perspective_16\n",
      "perspective_43\n",
      "perspective_6\n",
      "perspective_22\n",
      "perspective_121\n",
      "perspective_144\n",
      "perspective_150\n",
      "perspective_34\n",
      "perspective_95\n",
      "perspective_131\n",
      "perspective_71\n",
      "perspective_84\n",
      "perspective_60\n",
      "perspective_62\n",
      "perspective_145\n",
      "perspective_86\n",
      "perspective_141\n",
      "perspective_93\n",
      "perspective_129\n",
      "perspective_69\n",
      "perspective_48\n",
      "perspective_3\n",
      "perspective_149\n",
      "perspective_81\n",
      "perspective_106\n",
      "perspective_14\n",
      "perspective_97\n",
      "perspective_137\n",
      "perspective_70\n",
      "perspective_107\n",
      "perspective_54\n",
      "perspective_13\n",
      "perspective_75\n",
      "perspective_73\n",
      "perspective_146\n",
      "perspective_50\n",
      "perspective_64\n",
      "perspective_126\n",
      "perspective_11\n",
      "perspective_132\n",
      "perspective_47\n",
      "perspective_4\n",
      "perspective_35\n",
      "perspective_125\n",
      "perspective_140\n",
      "perspective_120\n",
      "perspective_1\n",
      "perspective_114\n",
      "perspective_12\n",
      "perspective_38\n",
      "perspective_74\n",
      "perspective_78\n",
      "perspective_18\n",
      "perspective_122\n",
      "perspective_29\n",
      "perspective_118\n",
      "perspective_87\n",
      "perspective_113\n",
      "perspective_49\n",
      "perspective_51\n",
      "perspective_80\n",
      "perspective_66\n",
      "perspective_44\n",
      "perspective_27\n",
      "perspective_115\n",
      "perspective_33\n",
      "perspective_143\n",
      "perspective_79\n",
      "perspective_142\n",
      "perspective_112\n",
      "perspective_147\n",
      "perspective_123\n",
      "perspective_102\n",
      "perspective_90\n",
      "perspective_101\n",
      "perspective_110\n",
      "perspective_99\n",
      "perspective_72\n",
      "perspective_127\n",
      "perspective_148\n",
      "perspective_2\n",
      "perspective_91\n",
      "perspective_103\n",
      "perspective_30\n",
      "perspective_67\n",
      "perspective_31\n",
      "perspective_61\n",
      "perspective_92\n",
      "perspective_98\n",
      "perspective_77\n",
      "perspective_104\n",
      "perspective_42\n",
      "perspective_68\n",
      "perspective_111\n",
      "perspective_59\n",
      "perspective_32\n",
      "perspective_136\n",
      "perspective_119\n",
      "perspective_116\n",
      "perspective_108\n",
      "perspective_133\n",
      "perspective_41\n",
      "perspective_58\n",
      "perspective_7\n",
      "perspective_134\n",
      "perspective_26\n",
      "perspective_94\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "warped_images = []\n",
    "\n",
    "for i in range(0, 150):\n",
    "    image_name = images_p[i].split('/')[-1].split('.')[-2]\n",
    "    perspective_image = read_image(i, images_p, 1)\n",
    "#     perspective_image = read_image(i, perspective_images, 1)\n",
    "    warped = warp_image(template_image, perspective_image)\n",
    "#     show_image(warped)\n",
    "    cv.imwrite('./warped_perspective/' + image_name + '.jpg', warped) \n",
    "    warped_images.append([warped, image_name])\n",
    "    print (image_name)\n",
    "    \n",
    "print (\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# image_n = read_image(0, images_n, 0.5)\n",
    "# image_r = read_image(0, rotated_images, 0.5)\n",
    "# image_p = read_image(0, perspective_images, 0.5)\n",
    "# # show_image(warped_images[0])\n",
    "# resized_n = cv.resize(image_n, (0,0), fx=0.5, fy=0.5)\n",
    "# resized_r = cv.resize(image_r, (0,0), fx=0.5, fy=0.5)\n",
    "# resized_p = cv.resize(image_p, (0,0), fx=0.5, fy=0.5)\n",
    "# # show_image(resized)\n",
    "# table1_n = get_first_grid(resized_n)\n",
    "# table1_r = get_first_grid(resized_r)\n",
    "# table1_p = get_first_grid(resized_p)\n",
    "\n",
    "# table2_n = get_second_grid(resized_n)\n",
    "# table2_r = get_second_grid(resized_r)\n",
    "# table2_p = get_second_grid(resized_p)\n",
    "\n",
    "# show_image(table1_n)\n",
    "# # show_image(table1_r)\n",
    "# # show_image(table1_p)\n",
    "# # cv.imwrite('./table1_n.jpg', table1_n) \n",
    "# # show_image(table2_n)\n",
    "# # show_image(table2_r)\n",
    "# # show_image(table2_p)\n",
    "# # show_image(table2)\n",
    "# table_x1 = find_x_from_table(table1_p)\n",
    "# table_x2 = find_x_from_table(table2_r)\n",
    "# show_image(table_x1[1])\n",
    "# # show_image(table_x2)\n",
    "# # print(warped_images[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
