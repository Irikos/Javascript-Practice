{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I am attempting to solve the first scenario of the requirements\n",
    "# most of the stuff to solve this is done in the labs\n",
    "# Scenario 1 (real world) - you receive a test set containing 55 scanned images annotated with the option (F or I) and with the digit (1, 2, 3 or 4). For each image you have\n",
    "# to output the corresponding grade. Each correctly labeled scanned image will worth\n",
    "# 0.03 points for a total of 1.65 points;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basically, I will do the following steps:\n",
    "# 1. Apply filters on images and detect the edges (canny edge?)\n",
    "#    1.a grayscale the image\n",
    "#    1.b apply filter (gaussian, sobel?)\n",
    "#    1.c canny edge detection?\n",
    "# 2. Detect lines\n",
    "#    2.a Detect horizontal lines\n",
    "#    2.b Detect vertical lines\n",
    "#    2.c Merge image\n",
    "#3. Detect boxes and create an inside, smaller box, as to not count the edges\n",
    "#    3.a Detect boxes (lab 3.1)\n",
    "#    3.b Verify mean color inside the boxes and mark as green with X and red without X\n",
    "#    3.c Store the data and compare it to the answers in the files\n",
    "#    3.d Do this on all files and see accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# Required libraries to be installed: Pillow, OpenCV\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "# from google.colab.patches import cv2_imshow\n",
    "from IPython.display import clear_output, Image, display\n",
    "import PIL.Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = './Files/images/' # change this on your machine\n",
    "images = glob.glob(os.path.join(base_folder, \"image_*.jpg\")) \n",
    "char_to_index = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
    "image_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "\n",
    "# kernel size. h and v stand for orientation\n",
    "# hk_size = 3\n",
    "# vk_size = 3\n",
    "x_threshold = 240\n",
    "threshold_same_v_line = 20\n",
    "threshold_same_h_line = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show image function is taken from Andrei Manolache outside of the project scope, I trust it does not count as plagiarism \n",
    "def show_image(a, fmt='jpeg'):\n",
    "    a = np.uint8(np.clip(a, 0, 255))\n",
    "    f = io.BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))\n",
    "    \n",
    "def read_image(index):\n",
    "    image = cv.imread(images[index])\n",
    "    return cv.resize(image, (0, 0), fx=0.15, fy=0.15)\n",
    "\n",
    "def split_first_table(image):\n",
    "    image_h, image_w, channels = image.shape\n",
    "    return image[int(0.55 * image_h):int(image_h * 0.87), int(image_w * 0.1): int(image_w * 0.37)]\n",
    "\n",
    "def split_second_table(image):\n",
    "    image_h, image_w, channels = image.shape\n",
    "    return image[int(0.55 * image_h):int(image_h * 0.87), int(image_w * 0.60): int(image_w * 0.90)]\n",
    "\n",
    "def apply_filters(image):\n",
    "    image_gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    return image_gray\n",
    "\n",
    "def get_binary_image(image_gray):\n",
    "    mean_value = image_gray.mean()\n",
    "    _, image_th = cv.threshold(imgage_gray,meanValue, 255, cv.THRESH_BINARY_INV)\n",
    "\n",
    "def horizontal_kernel(hk_size=11):\n",
    "    kernel = np.array([hk_size * [0], hk_size * [1], hk_size * [0]])\n",
    "    kernel = kernel / kernel.sum()\n",
    "    return kernel\n",
    "\n",
    "def vertical_kernel(vk_size=11):\n",
    "    kernel = np.array(vk_size * [int(vk_size / 2) * [0] + [1] + int(vk_size / 2) * [0]])\n",
    "#     kernel = np.array([[0,1,0],[0,1,0],[0,1,0]])                \n",
    "    kernel = kernel / kernel.sum()\n",
    "    return kernel\n",
    "\n",
    "def filter_vertical(image_gray):    \n",
    "    mean_value = image_gray.mean()\n",
    "    _, image_th = cv.threshold(image_gray, mean_value, 255, cv.THRESH_BINARY_INV)\n",
    "    thresholded = image_th\n",
    "    filtered = 255 - cv.filter2D(255 - thresholded, -1, vertical_kernel())\n",
    "    filtered[filtered < 255] = 0\n",
    "    filtered_vertical = filtered\n",
    "    return filtered_vertical\n",
    "\n",
    "\n",
    "def filter_horizontal(image_gray):    \n",
    "    mean_value = image_gray.mean()\n",
    "    _, image_th = cv.threshold(image_gray, mean_value, 255, cv.THRESH_BINARY_INV)\n",
    "    thresholded = image_th\n",
    "    filtered = 255 - cv.filter2D(255 - thresholded, -1, horizontal_kernel())\n",
    "    filtered[filtered < 255] = 0\n",
    "    filtered_horizontal = filtered\n",
    "    return filtered_horizontal\n",
    "\n",
    "def get_horizontal_lines(image_gray, filtered_horizontal, num_lines):\n",
    "    mask = filtered_horizontal // 255\n",
    "    res = np.sum(mask, axis=1) \n",
    "    res = res.argsort() \n",
    "    h_img = np.dstack((filtered_horizontal, filtered_horizontal, filtered_horizontal))\n",
    "    h_lines = [] #  _ x \n",
    "    for i in range(num_lines+1):\n",
    "        cv.line(h_img, (0, res[-i]), (h_img.shape[1], res[-i]), (0, 0, 255), 2) \n",
    "        h_lines.append([(0, res[-i]), (h_img.shape[1], res[-i])])\n",
    "    \n",
    "    h_lines.sort(key=lambda coords: coords[0][1])\n",
    "    \n",
    "    #### h lines\n",
    "    distinct_h_lines = []   \n",
    "    distinct_h_lines.append(h_lines[0])\n",
    "\n",
    "    for line in h_lines:  \n",
    "        if line[0][1] - distinct_h_lines[-1][0][1] > threshold_same_h_line:\n",
    "            distinct_h_lines.append(line)   \n",
    "\n",
    "    # take the last 16 lines\n",
    "    correct_h_lines = distinct_h_lines[-16:] \n",
    "    print (correct_h_lines)\n",
    "    \n",
    "    return correct_h_lines\n",
    "\n",
    "def get_vertical_lines(image_gray, filtered_vertical, num_lines):\n",
    "    mask = filtered_vertical // 255\n",
    "    res = np.sum(mask, axis=0) \n",
    "    res = res.argsort() \n",
    "    v_img = np.dstack((filtered_vertical, filtered_vertical, filtered_vertical))\n",
    "    v_lines = [] #  _ x \n",
    "    for i in range(num_lines+1):\n",
    "        cv.line(v_img, (res[-i], 0), (res[-i], v_img.shape[0]), (0, 0, 255), 1) \n",
    "        v_lines.append([(res[-i], 0), (res[-i], v_img.shape[0])])\n",
    "    # de aici\n",
    "    v_lines.sort(key=lambda coords: coords[1][0])\n",
    "    #### v lines\n",
    "    distinct_v_lines = []   \n",
    "    distinct_v_lines.append(v_lines[0])\n",
    "# [[(0, 18), (167, 18)], \n",
    "# [(0, 35), (167, 35)], [(0, 53), (167, 53)], [(0, 70), (167, 70)], [(0, 87), (167, 87)], \n",
    "# [(0, 104), (167, 104)], [(0, 121), (167, 121)], [(0, 138), (167, 138)], [(0, 155), (167, 155)], \n",
    "# [(0, 172), (167, 172)], [(0, 189), (167, 189)], [(0, 206), (167, 206)], [(0, 223), (167, 223)], \n",
    "# [(0, 240), (167, 240)], [(0, 257), (167, 257)], [(0, 274), (167, 274)]]\n",
    "\n",
    "    for line in v_lines:  \n",
    "        if line[1][0] - distinct_v_lines[-1][1][0] > threshold_same_v_line:\n",
    "            distinct_v_lines.append(line)   \n",
    "    \n",
    "#     print (distinct_v_lines)\n",
    "    # take the last 16 lines\n",
    "#     print (len(v_lines))\n",
    "    automatic_v_lines = distinct_v_lines[-5:] \n",
    "\n",
    "    \n",
    "    #     for line in automatic_v_lines:\n",
    "#         line[0][0] = \n",
    "        \n",
    "        print (line[0][0])\n",
    "#         line[0][0] = ()\n",
    "#         line[1][0] = \n",
    "#     print (len(correct_v_lines))\n",
    "    return correct_v_lines\n",
    "\n",
    "def apply_lines(image):\n",
    "    image_gray = apply_filters(image)\n",
    "    image_h = filter_horizontal(image_gray)\n",
    "    image_v = filter_vertical(image_gray)\n",
    "    h_lines = get_horizontal_lines(image_gray, image_h, 60)\n",
    "    v_lines = get_vertical_lines(image_gray, image_v, 60)\n",
    "    \n",
    "    color_image = np.dstack((image_gray, image_gray, image_gray))\n",
    "    for line in v_lines: \n",
    "        cv.line(color_image, line[0], line[1], (255, 0, 0), 1) \n",
    "        \n",
    "    for line in h_lines: \n",
    "        cv.line(color_image, line[0], line[1], (0, 0, 255), 1)     \n",
    "    ###\n",
    "    return color_image\n",
    "\n",
    "def find_x_from_img(grayscale_image, vertical_lines, horizontal_lines, threshold):\n",
    "    # grayscale_image - input image containing the frame\n",
    "    # vertical_lines - list with the vertical lines\n",
    "    # horizontal_lines - list with horizontal lines\n",
    "    # threshold - simple 1D classifier    \n",
    "    appended = False\n",
    "    image = np.dstack((grayscale_image, grayscale_image, grayscale_image))\n",
    "    x_color = (0, 255, 0)  # plot a patch containing an X with green color\n",
    "    blank_color = (0, 0, 255)  # plot a patch containing a blank with red color\n",
    "    # crop each patch and display it\n",
    "    x_values = [] \n",
    "    for i in range(len(horizontal_lines) - 1):\n",
    "        appended = False\n",
    "        for j in range(len(vertical_lines) - 1):\n",
    "            x_min = vertical_lines[j][0][0] + 3\n",
    "            x_max = vertical_lines[j + 1][1][0] - 2\n",
    "            y_min = horizontal_lines[i][0][1] + 3\n",
    "            y_max = horizontal_lines[i + 1][1][1] - 2\n",
    "        \n",
    "            \n",
    "            patch = grayscale_image[y_min:y_max,x_min:x_max].copy()\n",
    "            mean_patch_value = np.round(patch.mean())\n",
    "            if(mean_patch_value <= threshold):\n",
    "              color = x_color\n",
    "              x_values.append(j)\n",
    "              appended = True\n",
    "            else:\n",
    "              color = blank_color\n",
    "            cv.rectangle(image, (x_min, y_min), (x_max, y_max), color=color, thickness=1)\n",
    "        if (appended == False):\n",
    "            x_values.append(0)\n",
    "#             cv.putText(image, str(mean_patch_value)[:3] ,(x_min + 10, y_min + 50), cv.FONT_HERSHEY_COMPLEX, 1, (0,0,0), 2) \n",
    "#     show_image(image)\n",
    "    return x_values\n",
    "\n",
    "def verify_result(ground_truth, detected_values):\n",
    "    for i in range(0, 15):\n",
    "        if (int(char_to_index[ground_truth[i][1]]) != detected_values[i]):\n",
    "            return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 18), (167, 18)], [(0, 35), (167, 35)], [(0, 53), (167, 53)], [(0, 70), (167, 70)], [(0, 87), (167, 87)], [(0, 104), (167, 104)], [(0, 121), (167, 121)], [(0, 138), (167, 138)], [(0, 155), (167, 155)], [(0, 172), (167, 172)], [(0, 189), (167, 189)], [(0, 206), (167, 206)], [(0, 223), (167, 223)], [(0, 240), (167, 240)], [(0, 257), (167, 257)], [(0, 274), (167, 274)]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-b44ff69001b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mimage_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_vertical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_lg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mh_lines_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_horizontal_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_lg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mv_lines_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_vertical_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_lg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mground_truth_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mground_truth_content\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-18697d7ad3f1>\u001b[0m in \u001b[0;36mget_vertical_lines\u001b[0;34m(image_gray, filtered_vertical, num_lines)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mcorrect_v_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistinct_v_lines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorrect_v_lines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;31m#         line[0][0] = ()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "# Take the last lines as reference and draw the rest manually.\n",
    "\n",
    "image_matching = np.empty((150,3))\n",
    "image_matching[:] = np.NaN\n",
    "for i in range(0,1):\n",
    "    # read image and apply lines on each table\n",
    "    image = read_image(i)\n",
    "    \n",
    "    image_name = images[i].split('/')[-1].split('.')[-2]\n",
    "    ground_truth_content = np.loadtxt(os.path.join(base_folder, '%s.txt' % image_name), dtype=str)\n",
    "#     print (image_name)\n",
    "    # left table: ground truth, v and h lines\n",
    "    image_left = split_first_table(image)\n",
    "    image_lg = apply_filters(image_left)\n",
    "    image_h = filter_horizontal(image_lg)\n",
    "    image_v = filter_vertical(image_lg)\n",
    "    h_lines_l = get_horizontal_lines(image_lg, image_h, 60)\n",
    "    v_lines_l = get_vertical_lines(image_lg, image_v, 60)\n",
    "    \n",
    "    ground_truth_left = ground_truth_content[1:16]\n",
    "    \n",
    "    \n",
    "    # right table: ground truth, v and h lines\n",
    "#     image_right = split_second_table(image)\n",
    "#     image_rg = apply_filters(image_right)\n",
    "#     image_h = filter_horizontal(image_rg)\n",
    "#     image_v = filter_vertical(image_rg)\n",
    "#     h_lines_r = get_horizontal_lines(image_rg, image_h, 60)\n",
    "#     v_lines_r = get_vertical_lines(image_rg, image_v, 60)\n",
    "    \n",
    "    ground_truth_right = ground_truth_content[16:-1]\n",
    "    \n",
    "    # get X-s, results and compare to ground truth\n",
    "#     results_left = find_x_from_img(image_lg, v_lines_l, h_lines_l, x_threshold)\n",
    "#     results_right = find_x_from_img(image_rg, v_lines_r, h_lines_r, x_threshold)\n",
    "#     image_matching[i][0] = verify_result(ground_truth_left, results_left)\n",
    "#     image_matching[i][1] = verify_result(ground_truth_right, results_right)\n",
    "#     image_matching[i][2] = (image_matching[i][0] + image_matching[i][1]) // 2\n",
    "#     print (image_matching[i][0], image_matching[i][1], image_matching[i][2])\n",
    "#     print (image_name, image_matching[i][0] == 1, image_matching[i][1] == 1, image_matching[i][2] == 1)\n",
    "\n",
    "#     show_image(apply_lines(image_left))\n",
    "#     show_image(apply_lines(image_right))\n",
    "# print (\"left:\")\n",
    "# print (image_matching)\n",
    "total = np.sum(image_matching, axis=0)\n",
    "print(total[0] * 100 / 150, total[1] * 100 / 150, total[2] * 100 / 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
