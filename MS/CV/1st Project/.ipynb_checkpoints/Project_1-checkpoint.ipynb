{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I am attempting to solve the first scenario of the requirements\n",
    "# most of the stuff to solve this is done in the labs\n",
    "# Scenario 1 (real world) - you receive a test set containing 55 scanned images annotated with the option (F or I) and with the digit (1, 2, 3 or 4). For each image you have\n",
    "# to output the corresponding grade. Each correctly labeled scanned image will worth\n",
    "# 0.03 points for a total of 1.65 points;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basically, I will do the following steps:\n",
    "# 1. Apply filters on images and detect the edges (canny edge?)\n",
    "#    1.a grayscale the image\n",
    "#    1.b apply filter (gaussian, sobel?)\n",
    "#    1.c canny edge detection?\n",
    "# 2. Detect lines\n",
    "#    2.a Detect horizontal lines\n",
    "#    2.b Detect vertical lines\n",
    "#    2.c Merge image\n",
    "#3. Detect boxes and create an inside, smaller box, as to not count the edges\n",
    "#    3.a Detect boxes (lab 3.1)\n",
    "#    3.b Verify mean color inside the boxes and mark as green with X and red without X\n",
    "#    3.c Store the data and compare it to the answers in the files\n",
    "#    3.d Do this on all files and see accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# Required libraries to be installed: Pillow, OpenCV\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "# from google.colab.patches import cv2_imshow\n",
    "from IPython.display import clear_output, Image, display\n",
    "import PIL.Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = './Files/images/' # change this on your machine\n",
    "images = glob.glob(os.path.join(base_folder, \"image_*.jpg\")) \n",
    "rotated_images = glob.glob(os.path.join(base_folder, \"rotation_*.jpg\")) \n",
    "perspective_images = glob.glob(os.path.join(base_folder, \"perspective_*.jpg\")) \n",
    "template_images = glob.glob(os.path.join(base_folder, \"template.jpg\")) \n",
    "char_to_index = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
    "image_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./Files/images/template.jpg']\n"
     ]
    }
   ],
   "source": [
    "# global variables\n",
    "\n",
    "# kernel size. h and v stand for orientation\n",
    "# hk_size = 3\n",
    "# vk_size = 3\n",
    "x_threshold = 247\n",
    "threshold_same_v_line = 20\n",
    "threshold_same_h_line = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show image function is taken from Andrei Manolache outside of the project scope, I trust it does not count as plagiarism \n",
    "def show_image(a, fmt='jpeg'):\n",
    "    a = np.uint8(np.clip(a, 0, 255))\n",
    "    f = io.BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))\n",
    "    \n",
    "def read_image(index, source):\n",
    "    image = cv.imread(source[index])\n",
    "    return cv.resize(image, (0, 0), fx=0.15, fy=0.15)\n",
    "\n",
    "def split_first_table(image):\n",
    "    image_h, image_w, channels = image.shape\n",
    "    return image[int(0.55 * image_h):int(image_h * 0.868), int(image_w * 0.1): int(image_w * 0.37)]\n",
    "\n",
    "def split_second_table(image):\n",
    "    image_h, image_w, channels = image.shape\n",
    "    return image[int(0.55 * image_h):int(image_h * 0.868), int(image_w * 0.60): int(image_w * 0.90)]\n",
    "\n",
    "def apply_filters(image):\n",
    "#     image_blur = cv.bilateralFilter(image,9 ,75 ,75)\n",
    "    image_blur = cv.medianBlur(image, 5)\n",
    "    image_gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    return image_gray\n",
    "\n",
    "def get_binary_image(image_gray):\n",
    "    mean_value = image_gray.mean()\n",
    "    _, image_th = cv.threshold(imgage_gray,meanValue, 255, cv.THRESH_BINARY_INV)\n",
    "\n",
    "def horizontal_kernel(hk_size=20):\n",
    "    kernel = np.array([hk_size * [0], hk_size * [1], hk_size * [0]])\n",
    "    kernel = kernel / kernel.sum()\n",
    "    return kernel\n",
    "\n",
    "def vertical_kernel(vk_size=20):\n",
    "    kernel = np.array(vk_size * [int(vk_size / 2) * [0] + [1] + int(vk_size / 2) * [0]])\n",
    "#     kernel = np.array([[0,1,0],[0,1,0],[0,1,0]])                \n",
    "    kernel = kernel / kernel.sum()\n",
    "    return kernel\n",
    "\n",
    "def filter_vertical(image_gray):    \n",
    "    mean_value = image_gray.mean()\n",
    "    _, image_th = cv.threshold(image_gray, mean_value, 255, cv.THRESH_BINARY_INV)\n",
    "    thresholded = image_th\n",
    "    filtered = 255 - cv.filter2D(255 - thresholded, -1, vertical_kernel())\n",
    "    filtered[filtered < 255] = 0\n",
    "    filtered_vertical = filtered\n",
    "    return filtered_vertical\n",
    "\n",
    "\n",
    "def filter_horizontal(image_gray):    \n",
    "    mean_value = image_gray.mean()\n",
    "    _, image_th = cv.threshold(image_gray, mean_value, 255, cv.THRESH_BINARY_INV)\n",
    "    thresholded = image_th\n",
    "    filtered = 255 - cv.filter2D(255 - thresholded, -1, horizontal_kernel())\n",
    "    filtered[filtered < 255] = 0\n",
    "    filtered_horizontal = filtered\n",
    "    return filtered_horizontal\n",
    "\n",
    "def get_horizontal_lines(image_gray, filtered_horizontal, num_lines):\n",
    "    mask = filtered_horizontal // 255\n",
    "    res = np.sum(mask, axis=1) \n",
    "    res = res.argsort() \n",
    "    h_img = np.dstack((filtered_horizontal, filtered_horizontal, filtered_horizontal))\n",
    "    h_lines = [] #  _ x \n",
    "    for i in range(num_lines+1):\n",
    "        cv.line(h_img, (0, res[-i]), (h_img.shape[1], res[-i]), (0, 0, 255), 2) \n",
    "        h_lines.append([(0, res[-i]), (h_img.shape[1], res[-i])])\n",
    "    \n",
    "    h_lines.sort(key=lambda coords: coords[0][1])\n",
    "    \n",
    "    #### h lines\n",
    "    distinct_h_lines = []   \n",
    "    distinct_h_lines.append(h_lines[0])\n",
    "\n",
    "    for line in h_lines:  \n",
    "        if line[0][1] - distinct_h_lines[-1][0][1] > threshold_same_h_line:\n",
    "            distinct_h_lines.append(line)   \n",
    "\n",
    "    # take the last 16 lines\n",
    "    automatic_h_lines = distinct_h_lines[-16:] \n",
    "    #[(0, 20), (186, 20)], [(0, 37), (186, 37)], [(0, 54), (186, 54)], [(0, 71), (186, 71)], \n",
    "    #[(0, 88), (186, 88)], [(0, 105), (186, 105)], [(0, 122), (186, 122)], [(0, 139), (186, 139)], \n",
    "    #[(0, 156), (186, 156)], [(0, 173), (186, 173)], [(0, 191), (186, 191)], [(0, 208), (186, 208)]\n",
    "    #, [(0, 225), (186, 225)], [(0, 242), (186, 242)], [(0, 259), (186, 259)], \n",
    "    #[(0, 276), (186, 276)]]\n",
    "\n",
    "    correct_h_lines = np.zeros((16,2,2), dtype=object)\n",
    "#     print (correct_h_lines)\n",
    "    column_height = 17\n",
    "    line_width = 186\n",
    "    correct_h_lines[15] = automatic_h_lines[-1]\n",
    "    for i in range(14, -1, -1):\n",
    "        correct_h_lines[i][0][0] = correct_h_lines[i + 1][0][0] \n",
    "        correct_h_lines[i][0][1] = correct_h_lines[i + 1][0][1] - column_height\n",
    "        correct_h_lines[i][1][0] = correct_h_lines[i + 1][0][0] + line_width\n",
    "        correct_h_lines[i][1][1] = correct_h_lines[i + 1][0][1] - column_height\n",
    "        \n",
    "    return correct_h_lines\n",
    "\n",
    "def get_vertical_lines(image_gray, filtered_vertical, num_lines):\n",
    "    mask = filtered_vertical // 255\n",
    "    res = np.sum(mask, axis=0) \n",
    "    res = res.argsort() \n",
    "    v_img = np.dstack((filtered_vertical, filtered_vertical, filtered_vertical))\n",
    "    v_lines = [] #  _ x \n",
    "    for i in range(num_lines+1):\n",
    "        cv.line(v_img, (res[-i], 0), (res[-i], v_img.shape[0]), (0, 0, 255), 1) \n",
    "        v_lines.append([(res[-i], 0), (res[-i], v_img.shape[0])])\n",
    "    # de aici\n",
    "    v_lines.sort(key=lambda coords: coords[1][0])\n",
    "    #### v lines\n",
    "    distinct_v_lines = []   \n",
    "    distinct_v_lines.append(v_lines[0])\n",
    "# [[(0, 18), (167, 18)], \n",
    "# [(0, 35), (167, 35)], [(0, 53), (167, 53)], [(0, 70), (167, 70)], [(0, 87), (167, 87)], \n",
    "# [(0, 104), (167, 104)], [(0, 121), (167, 121)], [(0, 138), (167, 138)], [(0, 155), (167, 155)], \n",
    "# [(0, 172), (167, 172)], [(0, 189), (167, 189)], [(0, 206), (167, 206)], [(0, 223), (167, 223)], \n",
    "# [(0, 240), (167, 240)], [(0, 257), (167, 257)], [(0, 274), (167, 274)]]\n",
    "\n",
    "    for line in v_lines:  \n",
    "        if line[1][0] - distinct_v_lines[-1][1][0] > threshold_same_v_line:\n",
    "            distinct_v_lines.append(line)   \n",
    "    \n",
    "#     print (distinct_v_lines)\n",
    "    # take the last 5 lines\n",
    "#     print (len(v_lines))\n",
    "    automatic_v_lines = distinct_v_lines[-5:] \n",
    "\n",
    "    correct_v_lines = np.empty((5,2,2), dtype=object)\n",
    "    \n",
    "    \n",
    "    column_width = 22\n",
    "    \n",
    "    # automate in a for loop\n",
    "    correct_v_lines[4][0][0] = automatic_v_lines[4][0][0]\n",
    "    correct_v_lines[4][0][1] = automatic_v_lines[4][0][1] # 0, min y\n",
    "    correct_v_lines[4][1][0] = automatic_v_lines[4][0][0]\n",
    "    correct_v_lines[4][1][1] = automatic_v_lines[4][1][1] # max y\n",
    "    \n",
    "    correct_v_lines[3][0][0] = correct_v_lines[4][0][0] - column_width\n",
    "    correct_v_lines[3][0][1] = correct_v_lines[4][0][1] # 0, min y\n",
    "    correct_v_lines[3][1][0] = correct_v_lines[4][0][0] - column_width\n",
    "    correct_v_lines[3][1][1] = automatic_v_lines[4][1][1] # max y\n",
    "    \n",
    "    column_width -= 1\n",
    "    \n",
    "    correct_v_lines[2][0][0] = correct_v_lines[3][0][0] - column_width\n",
    "    correct_v_lines[2][0][1] = correct_v_lines[4][0][1] # 0, min y\n",
    "    correct_v_lines[2][1][0] = correct_v_lines[3][0][0] - column_width\n",
    "    correct_v_lines[2][1][1] = correct_v_lines[4][1][1] # max y\n",
    "    \n",
    "    correct_v_lines[1][0][0] = correct_v_lines[2][0][0] - column_width\n",
    "    correct_v_lines[1][0][1] = correct_v_lines[4][0][1] # 0, min y\n",
    "    correct_v_lines[1][1][0] = correct_v_lines[2][0][0] - column_width\n",
    "    correct_v_lines[1][1][1] = correct_v_lines[4][1][1] # max y\n",
    "    \n",
    "    correct_v_lines[0][0][0] = correct_v_lines[1][0][0] - column_width\n",
    "    correct_v_lines[0][0][1] = correct_v_lines[4][0][1] # 0, min y\n",
    "    correct_v_lines[0][1][0] = correct_v_lines[1][0][0] - column_width\n",
    "    correct_v_lines[0][1][1] = correct_v_lines[4][1][1] # max y\n",
    "        \n",
    "    return correct_v_lines\n",
    "\n",
    "def apply_lines(image):\n",
    "    image_gray = apply_filters(image)\n",
    "    image_h = filter_horizontal(image_gray)\n",
    "    image_v = filter_vertical(image_gray)\n",
    "    h_lines = get_horizontal_lines(image_gray, image_h, 60)\n",
    "    v_lines = get_vertical_lines(image_gray, image_v, 60)\n",
    "    \n",
    "    color_image = np.dstack((image_gray, image_gray, image_gray))\n",
    "    for line in v_lines: \n",
    "        cv.line(color_image, tuple(line[0]), tuple(line[1]), (255, 0, 0), 1) \n",
    "        \n",
    "    for line in h_lines: \n",
    "        cv.line(color_image, tuple(line[0]), tuple(line[1]), (0, 0, 255), 1)     \n",
    "    ###\n",
    "    return color_image\n",
    "\n",
    "def find_x_from_img(grayscale_image, vertical_lines, horizontal_lines, threshold):\n",
    "    # grayscale_image - input image containing the frame\n",
    "    # vertical_lines - list with the vertical lines\n",
    "    # horizontal_lines - list with horizontal lines\n",
    "    # threshold - simple 1D classifier    \n",
    "    appended = False\n",
    "    image = np.dstack((grayscale_image, grayscale_image, grayscale_image))\n",
    "    x_color = (0, 255, 0)  # plot a patch containing an X with green color\n",
    "    blank_color = (0, 0, 255)  # plot a patch containing a blank with red color\n",
    "    # crop each patch and display it\n",
    "    x_values = [] \n",
    "    for i in range(len(horizontal_lines) - 1):\n",
    "        appended = False\n",
    "        for j in range(len(vertical_lines) - 1):\n",
    "            x_min = vertical_lines[j][0][0] + 4\n",
    "            x_max = vertical_lines[j + 1][1][0] - 4\n",
    "            y_min = horizontal_lines[i][0][1] + 4\n",
    "            y_max = horizontal_lines[i + 1][1][1] - 3\n",
    "        \n",
    "            \n",
    "            patch = grayscale_image[y_min:y_max,x_min:x_max].copy()\n",
    "            mean_patch_value = np.round(patch.mean())\n",
    "            if(mean_patch_value <= threshold):\n",
    "              color = x_color\n",
    "              x_values.append(j)\n",
    "              appended = True\n",
    "            else:\n",
    "              color = blank_color\n",
    "            cv.rectangle(image, (x_min, y_min), (x_max, y_max), color=color, thickness=1)\n",
    "        if (appended == False):\n",
    "            x_values.append(0)\n",
    "#             cv.putText(image, str(mean_patch_value)[:3] ,(x_min + 10, y_min + 50), cv.FONT_HERSHEY_COMPLEX, 1, (0,0,0), 2) \n",
    "#     show_image(image)\n",
    "    return (x_values, image)\n",
    "\n",
    "def verify_result(ground_truth, detected_values):\n",
    "    for i in range(0, 15):\n",
    "        if (int(char_to_index[ground_truth[i][1]]) != detected_values[i]):\n",
    "            return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9f02ce5cff69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# read image and apply lines on each table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mimage_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-b71df870119b>\u001b[0m in \u001b[0;36mread_image\u001b[0;34m(index)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Take the last lines as reference and draw the rest manually.\n",
    "\n",
    "image_matching = np.empty((150,3))\n",
    "image_matching[:] = np.NaN\n",
    "for i in range(0,150):\n",
    "    # read image and apply lines on each table\n",
    "    image = read_image(i)\n",
    "    \n",
    "    image_name = images[i].split('/')[-1].split('.')[-2]\n",
    "    ground_truth_content = np.loadtxt(os.path.join(base_folder, '%s.txt' % image_name), dtype=str)\n",
    "#     print (image_name)\n",
    "    # left table: ground truth, v and h lines\n",
    "    image_left = split_first_table(image)\n",
    "    image_lg = apply_filters(image_left)\n",
    "    image_h = filter_horizontal(image_lg)\n",
    "    image_v = filter_vertical(image_lg)\n",
    "    h_lines_l = get_horizontal_lines(image_lg, image_h, 60)\n",
    "    v_lines_l = get_vertical_lines(image_lg, image_v, 60)\n",
    "    \n",
    "    ground_truth_left = ground_truth_content[1:16]\n",
    "    \n",
    "    \n",
    "    # right table: ground truth, v and h lines\n",
    "    image_right = split_second_table(image)\n",
    "    image_rg = apply_filters(image_right)\n",
    "    image_h = filter_horizontal(image_rg)\n",
    "    image_v = filter_vertical(image_rg)\n",
    "    h_lines_r = get_horizontal_lines(image_rg, image_h, 60)\n",
    "    v_lines_r = get_vertical_lines(image_rg, image_v, 60)\n",
    "    \n",
    "    ground_truth_right = ground_truth_content[16:-1]\n",
    "    \n",
    "    # get X-s, results and compare to ground truth\n",
    "    results_left = find_x_from_img(image_lg, v_lines_l, h_lines_l, x_threshold)[0]\n",
    "    results_right = find_x_from_img(image_rg, v_lines_r, h_lines_r, x_threshold)[0]\n",
    "    image_matching[i][0] = verify_result(ground_truth_left, results_left)\n",
    "    image_matching[i][1] = verify_result(ground_truth_right, results_right)\n",
    "    image_matching[i][2] = (image_matching[i][0] + image_matching[i][1]) // 2\n",
    "    if (image_matching[i][0] != 1):\n",
    "        show_image(find_x_from_img(image_lg, v_lines_l, h_lines_l, x_threshold)[1])\n",
    "        print (image_name, i)\n",
    "    if (image_matching[i][1] != 1):\n",
    "        show_image(find_x_from_img(image_rg, v_lines_r, h_lines_r, x_threshold)[1])\n",
    "        print (image_name, i)\n",
    "#     print (image_matching[i][0], image_matching[i][1], image_matching[i][2])\n",
    "#     print (image_name, image_matching[i][0] == 1, image_matching[i][1] == 1, image_matching[i][2] == 1)\n",
    "\n",
    "#     show_image(apply_lines(image_left))\n",
    "#     show_image(apply_lines(image_right))\n",
    "# print (\"left:\")\n",
    "# print (image_matching)\n",
    "total = np.sum(image_matching, axis=0)\n",
    "print(total[0] * 100 / 150, total[1] * 100 / 150, total[2] * 100 / 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'clip' did not contain a loop with signature matching types (dtype('<U27'), dtype('<U27'), dtype('<U27')) -> dtype('<U27')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b0b89b6aa769>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-b71df870119b>\u001b[0m in \u001b[0;36mshow_image\u001b[0;34m(a, fmt)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# show image function is taken from Andrei Manolache outside of the project scope, I trust it does not count as plagiarism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'jpeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mclip\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ComputerVision/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mclip\u001b[0;34m(a, a_min, a_max, out, **kwargs)\u001b[0m\n\u001b[1;32m   2082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m     \"\"\"\n\u001b[0;32m-> 2084\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'clip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ComputerVision/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbound\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ComputerVision/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ComputerVision/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_clip\u001b[0;34m(a, min, max, out, casting, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         return _clip_dep_invoke_with_casting(\n\u001b[0;32m--> 132\u001b[0;31m             um.clip, a, min, max, out=out, casting=casting, **kwargs)\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ComputerVision/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_clip_dep_invoke_with_casting\u001b[0;34m(ufunc, out, casting, *args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# try to deal with broken casting rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_UFuncOutputCastingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# Numpy 1.17.0, 2019-02-24\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'clip' did not contain a loop with signature matching types (dtype('<U27'), dtype('<U27'), dtype('<U27')) -> dtype('<U27')"
     ]
    }
   ],
   "source": [
    "template_image()\n",
    "show_image(template_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
